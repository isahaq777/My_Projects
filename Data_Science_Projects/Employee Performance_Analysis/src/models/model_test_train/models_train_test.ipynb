{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Gender  EducationBackground  MaritalStatus  EmpDepartment  \\\n",
      "0   32       0                    2              2              5   \n",
      "1   47       0                    2              2              5   \n",
      "2   40       0                    1              1              5   \n",
      "3   41       0                    0              0              3   \n",
      "4   60       0                    2              2              5   \n",
      "\n",
      "   BusinessTravelFrequency  DistanceFromHome  EmpEducationLevel  \\\n",
      "0                        2                10                  3   \n",
      "1                        2                14                  4   \n",
      "2                        1                 5                  4   \n",
      "3                        2                10                  4   \n",
      "4                        2                16                  4   \n",
      "\n",
      "   EmpEnvironmentSatisfaction  EmpHourlyRate  ...  \\\n",
      "0                           4             55  ...   \n",
      "1                           4             42  ...   \n",
      "2                           4             48  ...   \n",
      "3                           2             73  ...   \n",
      "4                           1             84  ...   \n",
      "\n",
      "   EmpJobRole_Research Director  EmpJobRole_Research Scientist  \\\n",
      "0                             0                              0   \n",
      "1                             0                              0   \n",
      "2                             0                              0   \n",
      "3                             0                              0   \n",
      "4                             0                              0   \n",
      "\n",
      "   EmpJobRole_Sales Executive  EmpJobRole_Sales Representative  \\\n",
      "0                           1                                0   \n",
      "1                           1                                0   \n",
      "2                           1                                0   \n",
      "3                           0                                0   \n",
      "4                           1                                0   \n",
      "\n",
      "   EmpJobRole_Senior Developer  EmpJobRole_Senior Manager R&D  \\\n",
      "0                            0                              0   \n",
      "1                            0                              0   \n",
      "2                            0                              0   \n",
      "3                            0                              0   \n",
      "4                            0                              0   \n",
      "\n",
      "   EmpJobRole_Technical Architect  EmpJobRole_Technical Lead  \\\n",
      "0                               0                          0   \n",
      "1                               0                          0   \n",
      "2                               0                          0   \n",
      "3                               0                          0   \n",
      "4                               0                          0   \n",
      "\n",
      "   Mahalanobis_Dist  Outlier_Flag  \n",
      "0          2.899968         False  \n",
      "1          3.275450         False  \n",
      "2          4.549680         False  \n",
      "3          4.335864         False  \n",
      "4          3.366280         False  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "data_clean = pd.read_csv(\"E:\\My_Projects\\Data_Science_Projects\\Employee Performance_Analysis\\Data\\processed\")\n",
    "\n",
    "print(data_clean.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final numeric columns for scaling: ['NumCompaniesWorked', 'TotalWorkExperienceInYears', 'TrainingTimesLastYear', 'ExperienceYearsAtThisCompany', 'ExperienceYearsInCurrentRole', 'EmpEnvironmentSatisfaction', 'EmpLastSalaryHikePercent', 'YearsSinceLastPromotion', 'YearsWithCurrManager', 'EmpHourlyRate', 'EmpJobRole_Developer', 'EmpWorkLifeBalance', 'OverTime']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Classifier Accuracy: 0.9017857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.79        36\n",
      "           1       0.95      0.93      0.94       167\n",
      "           2       0.88      0.71      0.79        21\n",
      "\n",
      "    accuracy                           0.90       224\n",
      "   macro avg       0.86      0.84      0.84       224\n",
      "weighted avg       0.91      0.90      0.90       224\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:17:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:17:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:17:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:17:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:17:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Pipeline(steps=[('scaling',\n",
      "                 Pipeline(steps=[('preprocessor',\n",
      "                                  ColumnTransformer(remainder='passthrough',\n",
      "                                                    transformers=[('num',\n",
      "                                                                   StandardScaler(),\n",
      "                                                                   ['NumCompaniesWorked',\n",
      "                                                                    'TotalWorkExperienceInYears',\n",
      "                                                                    'TrainingTimesLastYear',\n",
      "                                                                    'ExperienceYearsAtThisCompany',\n",
      "                                                                    'ExperienceYearsInCurrentRole',\n",
      "                                                                    'EmpEnvironmentSatisfaction',\n",
      "                                                                    'EmpLastSalaryHikePercent',\n",
      "                                                                    'YearsSinceLastPromotion',\n",
      "                                                                    'YearsWithCurrManager',\n",
      "                                                                    'EmpHourlyRate',\n",
      "                                                                    'EmpJobRole_Developer',\n",
      "                                                                    'EmpWorkLifeBalance',\n",
      "                                                                    'OverTime'])]))])),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('feature_engineering', PolynomialFeatures(include_bias=False)),\n",
      "                ('classifier', RandomForestClassifier(random_state=42))])\n",
      "Best Accuracy (cv): 0.9194526395078777\n",
      "Test Set Accuracy of Best Model: 0.9017857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.79        36\n",
      "           1       0.95      0.93      0.94       167\n",
      "           2       0.88      0.71      0.79        21\n",
      "\n",
      "    accuracy                           0.90       224\n",
      "   macro avg       0.86      0.84      0.84       224\n",
      "weighted avg       0.91      0.90      0.90       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== Preprocessing: Re-map target variable =====\n",
    "# Our original target values are [2,3,4]. For models like XGBoost, I remap them to [0,1,2].\n",
    "data_processed = data_clean.copy()  # Work on a copy of your data\n",
    "data_processed['PerformanceRating'] = data_processed['PerformanceRating'].map({2: 0, 3: 1, 4: 2})\n",
    "\n",
    "# ===== Prepare Numeric Columns =====\n",
    "# Defined the list of numeric columns for scaling/normalization.\n",
    "numeric_cols = [\n",
    "    'NumCompaniesWorked', 'TotalWorkExperienceInYears', 'TrainingTimesLastYear',\n",
    "    'ExperienceYearsAtThisCompany', 'ExperienceYearsInCurrentRole','EmpEnvironmentSatisfaction',\n",
    "    'EmpLastSalaryHikePercent', 'YearsSinceLastPromotion', 'YearsWithCurrManager',\n",
    "    'EmpHourlyRate','EmpJobRole_Developer', 'EmpWorkLifeBalance', 'OverTime',\n",
    "    'EmpJobRole_Technical Lead'\n",
    "]\n",
    "\n",
    "# Remove any column that is constant (only one unique value) because they don’t add any information.\n",
    "numeric_cols = [col for col in numeric_cols if data_processed[col].nunique() > 1]\n",
    "print(\"Final numeric columns for scaling:\", numeric_cols)\n",
    "\n",
    "# ===== Separate Features and Target =====\n",
    "X = data_processed.drop(columns=['PerformanceRating'])\n",
    "y = data_processed['PerformanceRating']\n",
    "\n",
    "# ===== Preprocessing Pipeline for Numeric Columns =====\n",
    "# I apply StandardScaler to the numeric columns.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # leave other columns unchanged\n",
    ")\n",
    "\n",
    "# ===== Build the Overall Pipeline =====\n",
    "# I include scaling, feature selection, and polynomial feature expansion.\n",
    "pipeline = Pipeline([\n",
    "    ('scaling', Pipeline([\n",
    "        ('preprocessor', preprocessor)\n",
    "    ])),\n",
    "    ('feature_selection', SelectKBest(score_func=f_classif, k=10)),\n",
    "    ('feature_engineering', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    # The final classifier is a placeholder that will be set via GridSearchCV.\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# ===== Split the Data =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ===== Initial Training & Evaluation with RandomForest =====\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"RandomForest Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ===== Model Comparison via GridSearchCV =====\n",
    "# I try four classifiers: RandomForest, LogisticRegression, SVM, and XGBoost.\n",
    "# Note: For LogisticRegression, I increased max_iter to 500.\n",
    "param_grid = {\n",
    "    'classifier': [\n",
    "        RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        LogisticRegression(max_iter=500, random_state=42),\n",
    "        SVC(probability=True, random_state=42),\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "    ]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', error_score='raise')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Model:\", grid.best_estimator_)\n",
    "print(\"Best Accuracy (cv):\", grid.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(\"Test Set Accuracy of Best Model:\", accuracy_score(y_test, y_pred_best))\n",
    "print(classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final numeric columns for scaling: ['NumCompaniesWorked', 'TotalWorkExperienceInYears', 'TrainingTimesLastYear', 'ExperienceYearsAtThisCompany', 'ExperienceYearsInCurrentRole', 'EmpEnvironmentSatisfaction', 'EmpLastSalaryHikePercent', 'YearsSinceLastPromotion', 'YearsWithCurrManager', 'EmpHourlyRate', 'EmpJobRole_Developer', 'EmpWorkLifeBalance', 'OverTime']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Classifier Accuracy: 0.9017857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.79        36\n",
      "           1       0.95      0.93      0.94       167\n",
      "           2       0.88      0.71      0.79        21\n",
      "\n",
      "    accuracy                           0.90       224\n",
      "   macro avg       0.86      0.84      0.84       224\n",
      "weighted avg       0.91      0.90      0.90       224\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:17:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:17:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:17:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:17:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:17:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Pipeline(steps=[('scaling',\n",
      "                 Pipeline(steps=[('preprocessor',\n",
      "                                  ColumnTransformer(remainder='passthrough',\n",
      "                                                    transformers=[('num',\n",
      "                                                                   StandardScaler(),\n",
      "                                                                   ['NumCompaniesWorked',\n",
      "                                                                    'TotalWorkExperienceInYears',\n",
      "                                                                    'TrainingTimesLastYear',\n",
      "                                                                    'ExperienceYearsAtThisCompany',\n",
      "                                                                    'ExperienceYearsInCurrentRole',\n",
      "                                                                    'EmpEnvironmentSatisfaction',\n",
      "                                                                    'EmpLastSalaryHikePercent',\n",
      "                                                                    'YearsSinceLastPromotion',\n",
      "                                                                    'YearsWithCurrManager',\n",
      "                                                                    'EmpHourlyRate',\n",
      "                                                                    'EmpJobRole_Developer',\n",
      "                                                                    'EmpWorkLifeBalance',\n",
      "                                                                    'OverTime'])]))])),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('feature_engineering', PolynomialFeatures(include_bias=False)),\n",
      "                ('classifier', RandomForestClassifier(random_state=42))])\n",
      "Best Accuracy (cv): 0.9194526395078777\n",
      "Test Set Accuracy of Best Model: 0.9017857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.79        36\n",
      "           1       0.95      0.93      0.94       167\n",
      "           2       0.88      0.71      0.79        21\n",
      "\n",
      "    accuracy                           0.90       224\n",
      "   macro avg       0.86      0.84      0.84       224\n",
      "weighted avg       0.91      0.90      0.90       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== Preprocessing: Re-map target variable =====\n",
    "# Our original target values are [2,3,4]. For models like XGBoost, I remap them to [0,1,2].\n",
    "data_processed = data_clean.copy()  # Work on a copy of your data\n",
    "data_processed['PerformanceRating'] = data_processed['PerformanceRating'].map({2: 0, 3: 1, 4: 2})\n",
    "\n",
    "# ===== Prepare Numeric Columns =====\n",
    "# Define the list of numeric columns for scaling/normalization.\n",
    "numeric_cols = [\n",
    "    'NumCompaniesWorked', 'TotalWorkExperienceInYears', 'TrainingTimesLastYear',\n",
    "    'ExperienceYearsAtThisCompany', 'ExperienceYearsInCurrentRole','EmpEnvironmentSatisfaction',\n",
    "    'EmpLastSalaryHikePercent', 'YearsSinceLastPromotion', 'YearsWithCurrManager',\n",
    "    'EmpHourlyRate','EmpJobRole_Developer', 'EmpWorkLifeBalance', 'OverTime',\n",
    "    'EmpJobRole_Technical Lead'\n",
    "]\n",
    "\n",
    "# Remove any column that is constant (only one unique value) because they don’t add any information.\n",
    "numeric_cols = [col for col in numeric_cols if data_processed[col].nunique() > 1]\n",
    "print(\"Final numeric columns for scaling:\", numeric_cols)\n",
    "\n",
    "# ===== Separate Features and Target =====\n",
    "X = data_processed.drop(columns=['PerformanceRating'])\n",
    "y = data_processed['PerformanceRating']\n",
    "\n",
    "# ===== Preprocessing Pipeline for Numeric Columns =====\n",
    "# I apply StandardScaler to the numeric columns.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # leave other columns unchanged\n",
    ")\n",
    "\n",
    "# ===== Build the Overall Pipeline =====\n",
    "# I include scaling, feature selection, and polynomial feature expansion.\n",
    "pipeline = Pipeline([\n",
    "    ('scaling', Pipeline([\n",
    "        ('preprocessor', preprocessor)\n",
    "    ])),\n",
    "    ('feature_selection', SelectKBest(score_func=f_classif, k=10)),\n",
    "    ('feature_engineering', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    # The final classifier is a placeholder that will be set via GridSearchCV.\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# ===== Split the Data =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ===== Initial Training & Evaluation with RandomForest =====\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"RandomForest Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ===== Model Comparison via GridSearchCV =====\n",
    "# I try four classifiers: RandomForest, LogisticRegression, SVM, and XGBoost.\n",
    "# Note: For LogisticRegression, I increased max_iter to 500.\n",
    "param_grid = {\n",
    "    'classifier': [\n",
    "        RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        LogisticRegression(max_iter=500, random_state=42),\n",
    "        SVC(probability=True, random_state=42),\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "    ]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', error_score='raise')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Model:\", grid.best_estimator_)\n",
    "print(\"Best Accuracy (cv):\", grid.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(\"Test Set Accuracy of Best Model:\", accuracy_score(y_test, y_pred_best))\n",
    "print(classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE: Counter({1: 648, 0: 147, 2: 99})\n",
      "Class distribution after SMOTE: Counter({1: 648, 2: 648, 0: 648})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Check class distribution before SMOTE\n",
    "print(\"Class distribution before SMOTE:\", Counter(y_train))\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check class distribution after SMOTE\n",
    "print(\"Class distribution after SMOTE:\", Counter(y_train_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier(class_weight='balanced', random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The model is already performing well, with around 90% accuracy on the test set. However, there's still room for improvement, particularly in improving recall for class 2 and generalizing the model for unseen data. Below are several steps to enhance your model output:\n",
    "\n",
    "1. Improve Class Balance (Handle Class 2 Recall)\n",
    "🔹 Problem: Class 2 has lower recall, meaning the model is missing some true positives. This could be due to class imbalance.\n",
    "✅ Solution:\n",
    "Try SMOTE (Synthetic Minority Oversampling Technique) to generate synthetic examples for underrepresented classes.\n",
    "Use Class Weights in RandomForestClassifier to give more importance to class 2.\n",
    "Implementation\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Before SMOTE\n",
    "print(\"Class distribution before SMOTE:\", Counter(y_train))\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# After SMOTE\n",
    "print(\"Class distribution after SMOTE:\", Counter(y_train_resampled))\n",
    "Then, fit the model using X_train_resampled and y_train_resampled instead of X_train and y_train.\n",
    "\n",
    "Alternatively, modify RandomForestClassifier to penalize misclassifications of minority classes:\n",
    "\n",
    "\n",
    "RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "2. Feature Engineering Improvements\n",
    "🔹 Problem: The PolynomialFeatures step might be adding unnecessary complexity.\n",
    "✅ Solution:\n",
    "Try Interaction Features Instead of full polynomial expansion.\n",
    "Use Feature Importances from RandomForest to drop irrelevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Generate interaction features only (avoid full polynomial expansion)\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = best_model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Get transformed feature names (after PolynomialFeatures)\n",
    "feature_engineering = best_model.named_steps['feature_engineering']\n",
    "feature_selection = best_model.named_steps['feature_selection']\n",
    "selected_feature_names = feature_selection.get_feature_names_out()\n",
    "poly_feature_names = feature_engineering.get_feature_names_out(selected_feature_names)\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_idx = np.argsort(feature_importances)[::-1]\n",
    "n_features_to_plot = min(10, len(feature_importances))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(np.array(poly_feature_names)[sorted_idx[:n_features_to_plot]], \n",
    "         feature_importances[sorted_idx[:n_features_to_plot]])\n",
    "\n",
    "plt.xlabel(\"Feature Importance\", fontsize=12)\n",
    "plt.ylabel(\"Features\", fontsize=12)\n",
    "plt.title(f\"Top {n_features_to_plot} Most Important Features\", fontsize=14)\n",
    "\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# **Fix label display**\n",
    "plt.tight_layout()  # Adjust layout\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__max_depth': 48, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 3, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 326}\n",
      "Best CV Accuracy: 0.9306258238654197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': randint(100, 500),\n",
    "    'classifier__max_depth': randint(5, 50),\n",
    "    'classifier__min_samples_split': randint(2, 20),\n",
    "    'classifier__min_samples_leaf': randint(1, 10),\n",
    "    'classifier__max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best CV Accuracy:\", random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.79        36\n",
      "           1       0.95      0.93      0.94       167\n",
      "           2       0.88      0.71      0.79        21\n",
      "\n",
      "    accuracy                           0.90       224\n",
      "   macro avg       0.86      0.84      0.84       224\n",
      "weighted avg       0.91      0.90      0.90       224\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:20:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.89      0.79        36\n",
      "           1       0.96      0.89      0.92       167\n",
      "           2       0.68      0.81      0.74        21\n",
      "\n",
      "    accuracy                           0.88       224\n",
      "   macro avg       0.78      0.86      0.82       224\n",
      "weighted avg       0.89      0.88      0.88       224\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: CatBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.79        36\n",
      "           1       0.94      0.91      0.93       167\n",
      "           2       0.76      0.76      0.76        21\n",
      "\n",
      "    accuracy                           0.89       224\n",
      "   macro avg       0.81      0.84      0.83       224\n",
      "weighted avg       0.89      0.89      0.89       224\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4948\n",
      "[LightGBM] [Info] Number of data points in the train set: 894, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score -1.805273\n",
      "[LightGBM] [Info] Start training from score -0.321815\n",
      "[LightGBM] [Info] Start training from score -2.200586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [42 44] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\user\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LightGBM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.89      0.81        36\n",
      "           1       0.96      0.91      0.93       167\n",
      "           2       0.73      0.76      0.74        21\n",
      "\n",
      "    accuracy                           0.89       224\n",
      "   macro avg       0.81      0.85      0.83       224\n",
      "weighted avg       0.90      0.89      0.90       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline.set_params(classifier=model)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(f\"Model: {name}\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import classification_report\n",
    "#{'classifier__max_depth': 48, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 3, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 326}\n",
    "\n",
    "def tune_hyperparameters(pipeline, X_train, y_train, n_iter=30, cv=5):\n",
    "    \"\"\"Performs hyperparameter tuning using RandomizedSearchCV.\"\"\"\n",
    "    param_dist = {\n",
    "                'classifier__n_estimators': randint(100, 326),  # Specify a range\n",
    "                'classifier__max_depth': randint(1, 48),\n",
    "                'classifier__min_samples_split': randint(2, 20),  \n",
    "                'classifier__min_samples_leaf': randint(1, 10),  \n",
    "\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        pipeline, param_distributions=param_dist, n_iter=n_iter,\n",
    "        cv=cv, scoring='accuracy', n_jobs=-1, random_state=42\n",
    "    )\n",
    "    random_search.fit(X_train, y_train)\n",
    "    print(\"Best Parameters:\", random_search.best_params_)\n",
    "    print(\"Best CV Accuracy:\", random_search.best_score_)\n",
    "    return random_search.best_estimator_\n",
    "\n",
    "def evaluate_models(models, pipeline, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Fits different models using the given pipeline and evaluates their performance.\"\"\"\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        pipeline.set_params(classifier=model)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        results[name] = classification_report(y_test, y_pred, output_dict=True)\n",
    "        print(f\"Model: {name}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    return results\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='mlogloss', random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Define the optimized pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('feature_selection', SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42))),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, pipeline, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Fits different models using the given pipeline and evaluates their performance.\"\"\"\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        pipeline.set_params(classifier=model)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        weighted_avg = report.get(\"weighted avg\", {})\n",
    "\n",
    "        results[name] = {\n",
    "            \"accuracy\": report.get(\"accuracy\", 0),  # Accuracy is a float, not a dict\n",
    "            \"precision\": weighted_avg.get(\"precision\", 0),\n",
    "            \"recall\": weighted_avg.get(\"recall\", 0),\n",
    "            \"f1-score\": weighted_avg.get(\"f1-score\", 0)\n",
    "        }\n",
    "        \n",
    "        print(f\"Model: {name}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_performance(results):\n",
    "    \"\"\"Plots the classification performance metrics for different models.\"\"\"\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1-score']\n",
    "    model_names = list(results.keys())\n",
    "    \n",
    "    # Extract only the necessary values\n",
    "    scores = {metric: [results[model][metric] for model in model_names] for metric in metrics}\n",
    "    \n",
    "    df = pd.DataFrame(scores, index=model_names)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    df.plot(kind='bar', figsize=(12, 6), colormap='viridis')\n",
    "    plt.title(\"Model Performance Comparison\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Metric\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85        36\n",
      "           1       0.95      0.95      0.95       167\n",
      "           2       0.83      0.71      0.77        21\n",
      "\n",
      "    accuracy                           0.92       224\n",
      "   macro avg       0.87      0.85      0.86       224\n",
      "weighted avg       0.92      0.92      0.92       224\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82        36\n",
      "           1       0.96      0.92      0.94       167\n",
      "           2       0.71      0.81      0.76        21\n",
      "\n",
      "    accuracy                           0.90       224\n",
      "   macro avg       0.81      0.86      0.84       224\n",
      "weighted avg       0.90      0.90      0.90       224\n",
      "\n",
      "Model: CatBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84        36\n",
      "           1       0.96      0.93      0.95       167\n",
      "           2       0.77      0.81      0.79        21\n",
      "\n",
      "    accuracy                           0.92       224\n",
      "   macro avg       0.85      0.88      0.86       224\n",
      "weighted avg       0.92      0.92      0.92       224\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 545\n",
      "[LightGBM] [Info] Number of data points in the train set: 894, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.805273\n",
      "[LightGBM] [Info] Start training from score -0.321815\n",
      "[LightGBM] [Info] Start training from score -2.200586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model: LightGBM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81        36\n",
      "           1       0.95      0.93      0.94       167\n",
      "           2       0.76      0.76      0.76        21\n",
      "\n",
      "    accuracy                           0.90       224\n",
      "   macro avg       0.83      0.84      0.84       224\n",
      "weighted avg       0.90      0.90      0.90       224\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAJSCAYAAAC/R4R9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABzmElEQVR4nO3dd3yN5//H8ffJDpGYGQgpYjb2qFUrNUuV1qi9lVBFa1Ts2rtq75Haq6W2mFUzSm1F7D1CSCQ5vz/8cr5StGjk3JHX8/E4jzrXfd33/TmrOe9zX/d1m8xms1kAAAAAAMDqbKxdAAAAAAAAeIqQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAwNJPJpL59+772eufOnZPJZNKsWbPivab/Yu7cucqZM6fs7e2VMmVKa5eDRM6o73MAwJsjpAMA/tWsWbNkMplkMpm0Y8eO55abzWZ5e3vLZDLp448/tkKFby44ONjy2Ewmk+zt7ZUlSxY1btxYf/31V7zu6/jx42ratKmyZs2qqVOnasqUKfG6/aQqJCREDRs2lLe3txwdHZU6dWr5+/tr5syZio6OtnZ5AAC8FjtrFwAASDycnJwUFBSkUqVKxWnfunWrLl68KEdHRytV9t917NhRRYoU0ZMnT3TgwAFNmTJFq1ev1uHDh5U+ffp42UdwcLBiYmI0duxYZcuWLV62mdRNmzZNbdu2lYeHhxo1aiRfX1+FhYVp06ZNatGiha5cuaKePXtau8y3JnPmzHr06JHs7e2tXQoAIJ4Q0gEAr6xq1apavHixxo0bJzu7//0JCQoKUqFChXTz5k0rVvfflC5dWp999pkkqVmzZsqePbs6duyo2bNnq0ePHv9p2w8fPlTy5Ml1/fp1SYrXYe7h4eFKlixZvG0vMdm9e7fatm2r4sWLa82aNUqRIoVlWadOnbRv3z4dOXLEihW+PVFRUYqJiZGDg4OcnJysXQ4AIB4x3B0A8Mrq16+vW7duacOGDZa2yMhILVmyRF988cUL13n48KG6dOliGYqcI0cOjRgxQmazOU6/iIgIff3110qXLp1SpEihGjVq6OLFiy/c5qVLl9S8eXN5eHjI0dFRefLk0YwZM+LvgUoqX768JOns2bOWtl9//VWlS5dW8uTJlSJFClWrVk1//vlnnPWaNm0qFxcXnTlzRlWrVlWKFCnUoEED+fj4qE+fPpKkdOnSPXeu/YQJE5QnTx45Ojoqffr0at++ve7evRtn22XLltX777+v/fv368MPP1SyZMnUs2dPy3nJI0aM0I8//qgsWbIoWbJkqlixoi5cuCCz2awBAwYoY8aMcnZ21ieffKLbt2/H2fbKlStVrVo1pU+fXo6OjsqaNasGDBjw3HDx2BqOHj2qcuXKKVmyZMqQIYOGDRv23HP4+PFj9e3bV9mzZ5eTk5O8vLxUq1YtnTlzxtInJiZGY8aMUZ48eeTk5CQPDw+1adNGd+7c+dfXqF+/fjKZTJo/f36cgB6rcOHCatq0qeX+q74XTSaTAgICtHjxYuXOnVvOzs4qXry4Dh8+LEmaPHmysmXLJicnJ5UtW1bnzp176etUokQJOTs767333tOkSZPi9IuMjFTv3r1VqFAhubm5KXny5CpdurS2bNkSp9+zr++YMWOUNWtWOTo66ujRoy88J/3q1atq1qyZMmbMKEdHR3l5eemTTz55rs7Xec+9yusNAIgfHEkHALwyHx8fFS9eXD/99JOqVKki6WlwvXfvnurVq6dx48bF6W82m1WjRg1t2bJFLVq0UP78+bVu3Tp98803unTpkkaPHm3p27JlS82bN09ffPGFSpQooc2bN6tatWrP1XDt2jV98MEHliCVLl06/frrr2rRooXu37+vTp06xctjjQ2SadKkkfR0wrcmTZqoUqVKGjp0qMLDwzVx4kSVKlVKBw8elI+Pj2XdqKgoVapUSaVKldKIESOULFkyNW3aVHPmzNHy5cs1ceJEubi4KG/evJKkvn37ql+/fvL399eXX36pEydOaOLEidq7d6927twZZyjzrVu3VKVKFdWrV08NGzaUh4eHZdn8+fMVGRmpDh066Pbt2xo2bJjq1Kmj8uXLKzg4WN26ddPp06f1ww8/qGvXrnF+2Jg1a5ZcXFzUuXNnubi4aPPmzerdu7fu37+v4cOHx3lu7ty5o8qVK6tWrVqqU6eOlixZom7dusnPz8/yvoiOjtbHH3+sTZs2qV69evrqq68UFhamDRs26MiRI8qaNaskqU2bNpo1a5aaNWumjh076uzZsxo/frwOHjz43GN/Vnh4uDZt2qQPP/xQmTJl+tfX83Xei5K0fft2rVq1Su3bt5ckDR48WB9//LG+/fZbTZgwQe3atdOdO3c0bNgwNW/eXJs3b37uOapatarq1Kmj+vXra9GiRfryyy/l4OCg5s2bS5Lu37+vadOmqX79+mrVqpXCwsI0ffp0VapUSXv27FH+/PnjbHPmzJl6/PixWrdubTn3PiYm5rnHWrt2bf3555/q0KGDfHx8dP36dW3YsEGhoaGW9+nrvOde5fUGAMQjMwAA/2LmzJlmSea9e/eax48fb06RIoU5PDzcbDabzZ9//rm5XLlyZrPZbM6cObO5WrVqlvVWrFhhlmQeOHBgnO199tlnZpPJZD59+rTZbDabQ0JCzJLM7dq1i9Pviy++MEsy9+nTx9LWokULs5eXl/nmzZtx+tarV8/s5uZmqevs2bNmSeaZM2f+42PbsmWLWZJ5xowZ5hs3bpgvX75sXr16tdnHx8dsMpnMe/fuNYeFhZlTpkxpbtWqVZx1r169anZzc4vT3qRJE7Mkc/fu3Z/bV58+fcySzDdu3LC0Xb9+3ezg4GCuWLGiOTo62tI+fvx4S12xypQpY5ZknjRpUpztxj7WdOnSme/evWtp79Gjh1mSOV++fOYnT55Y2uvXr292cHAwP3782NIW+7w9q02bNuZkyZLF6Rdbw5w5cyxtERERZk9PT3Pt2rUtbTNmzDBLMo8aNeq57cbExJjNZrN5+/btZknm+fPnx1m+du3aF7Y/69ChQ2ZJ5q+++uqlfZ71qu9Fs9lslmR2dHQ0nz171tI2efJksySzp6en+f79+5b22Of42b6xz9HIkSMtbREREeb8+fOb3d3dzZGRkWaz2WyOiooyR0RExKnnzp07Zg8PD3Pz5s0tbbGvr6urq/n69etx+v/9fX7nzh2zJPPw4cNf+ly8yXvu315vAED8Ybg7AOC11KlTR48ePdIvv/yisLAw/fLLLy8d6r5mzRrZ2tqqY8eOcdq7dOkis9msX3/91dJP0nP9/n5U3Gw2a+nSpapevbrMZrNu3rxpuVWqVEn37t3TgQMH3uhxNW/eXOnSpVP69OlVrVo1PXz4ULNnz1bhwoW1YcMG3b17V/Xr14+zT1tbWxUrVuy54cmS9OWXX77Sfjdu3KjIyEh16tRJNjb/+7PcqlUrubq6avXq1XH6Ozo6qlmzZi/c1ueffy43NzfL/WLFikmSGjZsGGcOgWLFiikyMlKXLl2ytDk7O1v+HRYWpps3b6p06dIKDw/X8ePH4+zHxcVFDRs2tNx3cHBQ0aJF48yGv3TpUqVNm1YdOnR4rk6TySRJWrx4sdzc3PTRRx/FeV4LFSokFxeXFz6vse7fvy9JLxzm/iKv+l6MVaFChTijI2Kfy9q1a8fZZ2z7368EYGdnpzZt2ljuOzg4qE2bNrp+/br2798vSbK1tZWDg4Okp8P+b9++raioKBUuXPiF7+PatWsrXbp0//g4nZ2d5eDgoODg4JeeMvC677lXeb0BAPGH4e4AgNeSLl06+fv7KygoSOHh4YqOjrZMuPZ358+fV/r06Z8LUrly5bIsj/2vjY2NZQh0rBw5csS5f+PGDd29e1dTpkx56eXLYidne129e/dW6dKlZWtrq7Rp0ypXrlyWYHvq1ClJ/ztP/e9cXV3j3Lezs1PGjBlfab+xz8HfH6uDg4OyZMliWR4rQ4YMlmD3d38f9h0b2L29vV/Y/myI+/PPP9WrVy9t3rzZEoBj3bt3L879jBkzWoJ2rFSpUumPP/6w3D9z5oxy5MgR58eBvzt16pTu3bsnd3f3Fy7/p9cy9jkPCwt7aZ9nvep7MdZ/eS4lKX369EqePHmctuzZs0t6eo75Bx98IEmaPXu2Ro4cqePHj+vJkyeWvu+9995zj+FFbX/n6OiooUOHqkuXLvLw8NAHH3ygjz/+WI0bN5anp2ecx/qq77lXeb0BAPGHkA4AeG1ffPGFWrVqpatXr6pKlSrxOlv5P4k9/7Zhw4Zq0qTJC/vEnuf9uvz8/OTv7/+P+507d64l6Dzr70HU0dExzhHK+PTsEe+/s7W1fa128/9PmHb37l2VKVNGrq6u6t+/v7JmzSonJycdOHBA3bp1e+6853/b3quKiYmRu7u75s+f/8Ll/3TUOFu2bLKzs7NM5hbf3vS5fB3z5s1T06ZNVbNmTX3zzTdyd3eXra2tBg8eHGdyvVj/9No/q1OnTqpevbpWrFihdevWKTAwUIMHD9bmzZtVoECB164zPh8zAODfEdIBAK/t008/VZs2bbR7924tXLjwpf0yZ86sjRs3KiwsLM4RzNjh05kzZ7b8NyYmxnL0NdaJEyfibC925vfo6OiXBuq3IfYIv7u7e7zvN/Y5OHHihLJkyWJpj4yM1NmzZxPkcQYHB+vWrVtatmyZPvzwQ0v7szPbv66sWbPq999/15MnT146+VvWrFm1ceNGlSxZ8pUDaKxkyZKpfPny2rx5sy5cuPDcEe6/e9X3Yny5fPmy5dJ7sU6ePClJlmH0S5YsUZYsWbRs2bI4R6pjrwLwX2TNmlVdunRRly5ddOrUKeXPn18jR47UvHnzDPGeAwC8HOekAwBem4uLiyZOnKi+ffuqevXqL+1XtWpVRUdHa/z48XHaR48eLZPJZJkZOva/f58dfsyYMXHu29raqnbt2lq6dOkLr39948aNN3k4/6pSpUpydXXVoEGD4gxJjo/9+vv7y8HBQePGjYtzZHL69Om6d+/eC2e4j2+xR0qf3X9kZKQmTJjwxtusXbu2bt68+dxr/+x+6tSpo+joaA0YMOC5PlFRUc9dDuzv+vTpI7PZrEaNGunBgwfPLd+/f79mz54t6dXfi/ElKipKkydPttyPjIzU5MmTlS5dOhUqVEjSi5/333//Xb/99tsb7zc8PFyPHz+O05Y1a1alSJFCERERkozxngMAvBxH0gEAb+Rlw82fVb16dZUrV07fffedzp07p3z58mn9+vVauXKlOnXqZDlCnT9/ftWvX18TJkzQvXv3VKJECW3atEmnT59+bptDhgzRli1bVKxYMbVq1Uq5c+fW7du3deDAAW3cuPG563/HB1dXV02cOFGNGjVSwYIFVa9ePaVLl06hoaFavXq1SpYs+cIw+irSpUunHj16qF+/fqpcubJq1KihEydOaMKECSpSpEicCbvelhIlSihVqlRq0qSJOnbsKJPJpLlz5/6n4cyNGzfWnDlz1LlzZ+3Zs0elS5fWw4cPtXHjRrVr106ffPKJypQpozZt2mjw4MEKCQlRxYoVZW9vr1OnTmnx4sUaO3bsS+c7iK37xx9/VLt27ZQzZ041atRIvr6+CgsLU3BwsFatWqWBAwdKevX3YnxJnz69hg4dqnPnzil79uxauHChQkJCNGXKFMvIgo8//ljLli3Tp59+qmrVquns2bOaNGmScufO/cIfHV7FyZMnVaFCBdWpU0e5c+eWnZ2dli9frmvXrqlevXqSjPGeAwC8HCEdAPDW2NjYaNWqVerdu7cWLlyomTNnysfHR8OHD1eXLl3i9J0xY4bSpUun+fPna8WKFSpfvrxWr1793DBmDw8P7dmzR/3799eyZcs0YcIEpUmTRnny5NHQoUPf2mP54osvlD59eg0ZMkTDhw9XRESEMmTIoNKlS790tvVX1bdvX6VLl07jx4/X119/rdSpU6t169YaNGjQS4eKx6c0adLol19+UZcuXdSrVy+lSpVKDRs2VIUKFVSpUqU32qatra3WrFmj77//XkFBQVq6dKnSpEmjUqVKyc/Pz9Jv0qRJKlSokCZPnqyePXvKzs5OPj4+atiwoUqWLPmv+2nTpo2KFCmikSNHas6cObpx44ZcXFxUsGBBzZw50xI4X+e9GB9SpUql2bNnq0OHDpo6dao8PDw0fvx4tWrVytKnadOmunr1qiZPnqx169Ypd+7cmjdvnhYvXqzg4OA32q+3t7fq16+vTZs2ae7cubKzs1POnDm1aNEi1a5d29LP2u85AMDLmczM+gEAABBvypYtq5s3b77wlAwAAP4N56QDAAAAAGAQhHQAAAAAAAyCkA4AAAAAgEFwTjoAAAAAAAbBkXQAAAAAAAwiyV2CLSYmRpcvX1aKFClkMpmsXQ4AAAAA4B1nNpsVFham9OnTy8bmn4+VJ7mQfvny5eeuuQsAAAAAwNt24cIFZcyY8R/7JLmQniJFCklPnxxXV1crVwMAAAAAeNfdv39f3t7eljz6T5JcSI8d4u7q6kpIBwAAAAAkmFc55ZqJ4wAAAAAAMAhCOgAAAAAABkFIBwAAAADAIAjpAAAAAAAYBCEdAAAAAACDIKQDAAAAAGAQhHQAAAAAAAyCkA4AAAAAgEEQ0gEAAAAAMAhCOgAAAAAABkFIBwAAAADAIAjpAAAAAAAYBCEdAAAAAACDIKQDAAAAAGAQhHQAAAAAAAyCkA4AAAAAgEEQ0gEAAAAAMAhCOgAAAAAABkFIBwAAAADAIOysXQDeLQW/HG2V/R6Y+LVV9gsAAAAA8YmQ/g77yObzhN9pmxIJv09JRdf2TPB97s6/JMH3aeN5MsH3CQBIGPzQDQCQCOkAAABIYDFXsyf4PvmhG0BiQUgHAAD4G0ajvV278yf4LgEg0WDiOAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGwcRxAJCEWOMST1zeCQDwLuBvKBIKIR0AAABAopJUrsBgnasvLEnwfXKJxLgI6QCAdw7XYAYAAIkVIR0ArISjAG8P12AGAACJFRPHAQAAAABgEIR0AAAAAAAMgpAOAAAAAIBBENIBAAAAADAIQjoAAAAAAAZBSAcAAAAAwCAI6QAAAAAAGAQhHQAAAAAAgyCkAwAAAABgEIR0AAAAAAAMgpAOAAAAAIBBENIBAAAAADAIQjoAAAAAAAZBSAcAAAAAwCAI6QAAAAAAGAQhHQAAAAAAgyCkAwAAAABgEIR0AAAAAAAMgpAOAAAAAIBBENIBAAAAADAIQjoAAAAAAAZBSAcAAAAAwCAI6QAAAAAAGAQhHQAAAAAAgyCkAwAAAABgEIR0AAAAAAAMgpAOAAAAAIBBENIBAAAAADAIQjoAAAAAAAZBSAcAAAAAwCAI6QAAAAAAGAQhHQAAAAAAgyCkAwAAAABgEIR0AAAAAAAMgpAOAAAAAIBBENIBAAAAADAIQjoAAAAAAAZBSAcAAAAAwCAI6QAAAAAAGAQhHQAAAAAAgyCkAwAAAABgEIR0AAAAAAAMwuoh/ccff5SPj4+cnJxUrFgx7dmz5x/7jxkzRjly5JCzs7O8vb319ddf6/HjxwlULQAAAAAAb49VQ/rChQvVuXNn9enTRwcOHFC+fPlUqVIlXb9+/YX9g4KC1L17d/Xp00fHjh3T9OnTtXDhQvXs2TOBKwcAAAAAIP5ZNaSPGjVKrVq1UrNmzZQ7d25NmjRJyZIl04wZM17Yf9euXSpZsqS++OIL+fj4qGLFiqpfv/6/Hn0HAAAAACAxsFpIj4yM1P79++Xv7/+/Ymxs5O/vr99+++2F65QoUUL79++3hPK//vpLa9asUdWqVV+6n4iICN2/fz/ODQAAAAAAI7Kz1o5v3ryp6OhoeXh4xGn38PDQ8ePHX7jOF198oZs3b6pUqVIym82KiopS27Zt/3G4++DBg9WvX794rR0AAAAAgLfB6hPHvY7g4GANGjRIEyZM0IEDB7Rs2TKtXr1aAwYMeOk6PXr00L179yy3CxcuJGDFAAAAAAC8OqsdSU+bNq1sbW117dq1OO3Xrl2Tp6fnC9cJDAxUo0aN1LJlS0mSn5+fHj58qNatW+u7776Tjc3zvzk4OjrK0dEx/h8AAAAAAADxzGpH0h0cHFSoUCFt2rTJ0hYTE6NNmzapePHiL1wnPDz8uSBua2srSTKbzW+vWAAAAAAAEoDVjqRLUufOndWkSRMVLlxYRYsW1ZgxY/Tw4UM1a9ZMktS4cWNlyJBBgwcPliRVr15do0aNUoECBVSsWDGdPn1agYGBql69uiWsAwAAAACQWFk1pNetW1c3btxQ7969dfXqVeXPn19r1661TCYXGhoa58h5r169ZDKZ1KtXL126dEnp0qVT9erV9f3331vrIQAAAAAAEG+sGtIlKSAgQAEBAS9cFhwcHOe+nZ2d+vTpoz59+iRAZQAAAAAAJKxENbs7AAAAAADvMkI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIOwekj/8ccf5ePjIycnJxUrVkx79uz5x/53795V+/bt5eXlJUdHR2XPnl1r1qxJoGoBAAAAAHh77Ky584ULF6pz586aNGmSihUrpjFjxqhSpUo6ceKE3N3dn+sfGRmpjz76SO7u7lqyZIkyZMig8+fPK2XKlAlfPAAAAAAA8cyqIX3UqFFq1aqVmjVrJkmaNGmSVq9erRkzZqh79+7P9Z8xY4Zu376tXbt2yd7eXpLk4+Pzj/uIiIhQRESE5f79+/fj7wEAAAAAABCPrDbcPTIyUvv375e/v///irGxkb+/v3777bcXrrNq1SoVL15c7du3l4eHh95//30NGjRI0dHRL93P4MGD5ebmZrl5e3vH+2MBAAAAACA+WC2k37x5U9HR0fLw8IjT7uHhoatXr75wnb/++ktLlixRdHS01qxZo8DAQI0cOVIDBw586X569Oihe/fuWW4XLlyI18cBAAAAAEB8sepw99cVExMjd3d3TZkyRba2tipUqJAuXbqk4cOHq0+fPi9cx9HRUY6OjglcKQAAAAAAr89qIT1t2rSytbXVtWvX4rRfu3ZNnp6eL1zHy8tL9vb2srW1tbTlypVLV69eVWRkpBwcHN5qzQAAAAAAvE1WG+7u4OCgQoUKadOmTZa2mJgYbdq0ScWLF3/hOiVLltTp06cVExNjaTt58qS8vLwI6AAAAACARM+q10nv3Lmzpk6dqtmzZ+vYsWP68ssv9fDhQ8ts740bN1aPHj0s/b/88kvdvn1bX331lU6ePKnVq1dr0KBBat++vbUeAgAAAAAA8caq56TXrVtXN27cUO/evXX16lXlz59fa9eutUwmFxoaKhub//2O4O3trXXr1unrr79W3rx5lSFDBn311Vfq1q2btR4CAAAAAADxxuoTxwUEBCggIOCFy4KDg59rK168uHbv3v2WqwIAAAAAIOFZdbg7AAAAAAD4H0I6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQfynkB4ZGakTJ04oKioqvuoBAAAAACDJeqOQHh4erhYtWihZsmTKkyePQkNDJUkdOnTQkCFD4rVAAAAAAACSijcK6T169NChQ4cUHBwsJycnS7u/v78WLlwYb8UBAAAAAJCU2L3JSitWrNDChQv1wQcfyGQyWdrz5MmjM2fOxFtxAAAAAAAkJW90JP3GjRtyd3d/rv3hw4dxQjsAAAAAAHh1bxTSCxcurNWrV1vuxwbzadOmqXjx4vFTGQAAAAAAScwbDXcfNGiQqlSpoqNHjyoqKkpjx47V0aNHtWvXLm3dujW+awQAAAAAIEl4oyPppUqV0qFDhxQVFSU/Pz+tX79e7u7u+u2331SoUKH4rhEAAAAAgCThtY+kP3nyRG3atFFgYKCmTp36NmoCAAAAACBJeu0j6fb29lq6dOnbqAUAAAAAgCTtjYa716xZUytWrIjnUgAAAAAASNreaOI4X19f9e/fXzt37lShQoWUPHnyOMs7duwYL8UBAAAAAJCUvFFInz59ulKmTKn9+/dr//79cZaZTCZCOgAAAAAAb+CNQvrZs2fjuw4AAAAAAJK8Nzon/Vlms1lmszk+agEAAAAAIEl745A+Z84c+fn5ydnZWc7OzsqbN6/mzp0bn7UBAAAAAJCkvNFw91GjRikwMFABAQEqWbKkJGnHjh1q27atbt68qa+//jpeiwQAAAAAICl4o5D+ww8/aOLEiWrcuLGlrUaNGsqTJ4/69u1LSAcAAAAA4A280XD3K1euqESJEs+1lyhRQleuXPnPRQEAAAAAkBS9UUjPli2bFi1a9Fz7woUL5evr+5+LAgAAAAAgKXqj4e79+vVT3bp1tW3bNss56Tt37tSmTZteGN4BAAAAAMC/e6Mj6bVr19bvv/+utGnTasWKFVqxYoXSpk2rPXv26NNPP43vGgEAAAAASBLe6Ei6JBUqVEjz5s2Lz1oAAAAAAEjS3uhI+po1a7Ru3brn2tetW6dff/31PxcFAAAAAEBS9EYhvXv37oqOjn6u3Ww2q3v37v+5KAAAAAAAkqI3CumnTp1S7ty5n2vPmTOnTp8+/Z+LAgAAAAAgKXqjkO7m5qa//vrrufbTp08refLk/7koAAAAAACSojcK6Z988ok6deqkM2fOWNpOnz6tLl26qEaNGvFWHAAAAAAASckbhfRhw4YpefLkypkzp9577z299957ypkzp9KkSaMRI0bEd40AAAAAACQJb3QJNjc3N+3atUsbNmzQoUOH5OzsrHz58ql06dLxXR8AAAAAAEnGax1J/+233/TLL79IkkwmkypWrCh3d3eNGDFCtWvXVuvWrRUREfFWCgUAAAAA4F33WiG9f//++vPPPy33Dx8+rFatWumjjz5S9+7d9fPPP2vw4MHxXiQAAAAAAEnBa4X0kJAQVahQwXJ/wYIFKlq0qKZOnarOnTtr3LhxWrRoUbwXCQAAAABAUvBaIf3OnTvy8PCw3N+6dauqVKliuV+kSBFduHAh/qoDAAAAACAJea2Q7uHhobNnz0qSIiMjdeDAAX3wwQeW5WFhYbK3t4/fCgEAAAAASCJeK6RXrVpV3bt31/bt29WjRw8lS5Yszozuf/zxh7JmzRrvRQIAAAAAkBS81iXYBgwYoFq1aqlMmTJycXHR7Nmz5eDgYFk+Y8YMVaxYMd6LBAAAAAAgKXitkJ42bVpt27ZN9+7dk4uLi2xtbeMsX7x4sVxcXOK1QAAAAAAAkorXCumx3NzcXtieOnXq/1QMAAAAAABJ2Wudkw4AAAAAAN4eQjoAAAAAAAZBSAcAAAAAwCAI6QAAAAAAGAQhHQAAAAAAgyCkAwAAAABgEIR0AAAAAAAMgpAOAAAAAIBBENIBAAAAADAIQjoAAAAAAAZBSAcAAAAAwCAI6QAAAAAAGAQhHQAAAAAAgzBESP/xxx/l4+MjJycnFStWTHv27Hml9RYsWCCTyaSaNWu+3QIBAAAAAEgAVg/pCxcuVOfOndWnTx8dOHBA+fLlU6VKlXT9+vV/XO/cuXPq2rWrSpcunUCVAgAAAADwdlk9pI8aNUqtWrVSs2bNlDt3bk2aNEnJkiXTjBkzXrpOdHS0GjRooH79+ilLliwJWC0AAAAAAG+PVUN6ZGSk9u/fL39/f0ubjY2N/P399dtvv710vf79+8vd3V0tWrT4131ERETo/v37cW4AAAAAABiRVUP6zZs3FR0dLQ8PjzjtHh4eunr16gvX2bFjh6ZPn66pU6e+0j4GDx4sNzc3y83b2/s/1w0AAAAAwNtg9eHuryMsLEyNGjXS1KlTlTZt2ldap0ePHrp3757lduHChbdcJQAAAAAAb8bOmjtPmzatbG1tde3atTjt165dk6en53P9z5w5o3Pnzql69eqWtpiYGEmSnZ2dTpw4oaxZs8ZZx9HRUY6Ojm+hegAAAAAA4pdVj6Q7ODioUKFC2rRpk6UtJiZGmzZtUvHixZ/rnzNnTh0+fFghISGWW40aNVSuXDmFhIQwlB0AAAAAkKhZ9Ui6JHXu3FlNmjRR4cKFVbRoUY0ZM0YPHz5Us2bNJEmNGzdWhgwZNHjwYDk5Oen999+Ps37KlCkl6bl2AAAAAAASG6uH9Lp16+rGjRvq3bu3rl69qvz582vt2rWWyeRCQ0NlY5OoTp0HAAAAAOCNWD2kS1JAQIACAgJeuCw4OPgf1501a1b8FwQAAAAAgBVwiBoAAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBCEdAAAAAAADIKQDgAAAACAQdhZuwAAAN41ZrNZUVFRio6OtnYpeA22trays7OTyWSydikAgCSMkA4AQDyKjIzUlStXFB4ebu1S8AaSJUsmLy8va5cBAEjCCOkAAMSTmJgYnT17Vra2tkqfPr0cHBw4KptImM1mRUZG6saNG09fQzsbRUfFWLssAEASREgHACCeREZGKiYmRt7e3kqWLJm1y8FrcnZ2lr29vc6fP6+Unq66dfGutUsCACRBTBwHAEA8s7Hhz2tiFfva2djyGgIArIO/QAAAAAAAGAQhHQAAAAAAgyCkAwCAt8JkMmnFihXWLgMAgESFkA4AwDusadOmMplMatu27XPL2rdvL5PJpKZNm77StoKDg2UymXT37t1X6n/lyhVVqVLlNaoFAACEdAAA3nHe3t5asGCBHj16ZGl7/PixgoKClClTpnjfX2RkpCTJ09NTjo6O8b59AADeZYR0AADecQULFpS3t7eWLVtmaVu2bJkyZcqkAgUKWNpiYmI0ePBgvffee3J2dla+fPm0ZMkSSdK5c+dUrlw5SVKqVKniHIEvW7asAgIC1KlTJ6VNm1aVKlWS9Pxw94sXL6p+/fpKnTq1kidPrsKFC+v3339/y48eAIDEheukAwCQBDRv3lwzZ85UgwYNJEkzZsxQs2bNFBwcbOkzePBgzZs3T5MmTZKvr6+2bdumhg0bKl26dCpVqpSWLl2q2rVr68SJE3J1dZWzs7Nl3dmzZ+vLL7/Uzp07X7j/Bw8eqEyZMsqQIYNWrVolT09PHThwQDExMW/1cQMAkNgQ0gEASAIaNmyoHj166Pz585KknTt3asGCBZaQHhERoUGDBmnjxo0qXry4JClLlizasWOHJk+erDJlyih16tSSJHd3d6VMmTLO9n19fTVs2LCX7j8oKEg3btzQ3r17LdvJli1bPD9KAAASP0I6AABJQLp06VStWjXNmjVLZrNZ1apVU9q0aS3LT58+rfDwcH300Udx1ouMjIwzJP5lChUq9I/LQ0JCVKBAAUtABwAAL0ZIBwAgiWjevLkCAgIkST/++GOcZQ8ePJAkrV69WhkyZIiz7FUmf0uePPk/Ln92aDwAAHg5QjoAAElE5cqVFRkZKZPJZJncLVbu3Lnl6Oio0NBQlSlT5oXrOzg4SJKio6Nfe9958+bVtGnTdPv2bY6mAwDwD5jdHQCAJMLW1lbHjh3T0aNHZWtrG2dZihQp1LVrV3399deaPXu2zpw5owMHDuiHH37Q7NmzJUmZM2eWyWTSL7/8ohs3bliOvr+K+vXry9PTUzVr1tTOnTv1119/aenSpfrtt9/i9TECAJDYGSKk//jjj/Lx8ZGTk5OKFSumPXv2vLTv1KlTVbp0aaVKlUqpUqWSv7//P/YHAAD/4+rqKldX1xcuGzBggAIDAzV48GDlypVLlStX1urVq/Xee+9JkjJkyKB+/fqpe/fu8vDwsAydfxUODg5av3693N3dVbVqVfn5+WnIkCHP/VgAAEBSZ/Xh7gsXLlTnzp01adIkFStWTGPGjFGlSpV04sQJubu7P9c/ODhY9evXV4kSJeTk5KShQ4eqYsWK+vPPP587hw4AgKRu1qxZ/7j82euYm0wmffXVV/rqq69e2j8wMFCBgYFx2p69jNuzzGZznPuZM2e2XHcdAAC8mNWPpI8aNUqtWrVSs2bNlDt3bk2aNEnJkiXTjBkzXth//vz5ateunfLnz6+cOXNq2rRpiomJ0aZNmxK4cgAAAAAA4pdVQ3pkZKT2798vf39/S5uNjY38/f1f+Ry18PBwPXny5KWT0EREROj+/ftxbgAAAAAAGJFVQ/rNmzcVHR0tDw+POO0eHh66evXqK22jW7duSp8+fZyg/6zBgwfLzc3NcvP29v7PdQMAAAAA8DZYfbj7fzFkyBAtWLBAy5cvl5OT0wv79OjRQ/fu3bPcLly4kMBVAgAAAADwaqw6cVzatGlla2ura9euxWm/du2aPD09/3HdESNGaMiQIdq4caPy5s370n6Ojo5ydHSMl3oBAAAAAHibrHok3cHBQYUKFYoz6VvsJHDFixd/6XrDhg3TgAEDtHbtWhUuXDghSgUAAAAA4K2z+iXYOnfurCZNmqhw4cIqWrSoxowZo4cPH6pZs2aSpMaNGytDhgwaPHiwJGno0KHq3bu3goKC5OPjYzl33cXFRS4uLlZ7HAAAAAAA/FdWD+l169bVjRs31Lt3b129elX58+fX2rVrLZPJhYaGysbmfwf8J06cqMjISH322WdxttOnTx/17ds3IUsHAAAAACBeWT2kS1JAQIACAgJeuCw4ODjO/XPnzr39ggAAAAAAsAJDhHQAAN5lH9l8nqD72xCzOEH3BwAA4k+ivgQbAAAAAADvEkI6AAAwnCdPnli7BAAArIKQDgAAtHbtWpUqVUopU6ZUmjRp9PHHH+vMmTOW5RcvXlT9+vWVOnVqJU+eXIULF9bvv/9uWf7zzz+rSJEicnJyUtq0afXpp59alplMJq1YsSLO/lKmTKlZs2ZJejrfjMlk0sKFC1WmTBk5OTlp/vz5unXrlurXr68MGTIoWbJk8vPz008//RRnOzExMRo2bJiyZcsmR0dHZcqUSd9//70kqXz58s/NeXPjxg05ODjEufwrAABGQkgHAAB6+PChOnfurH379mnTpk2ysbHRp59+qpiYGD148EBlypTRpUuXtGrVKh06dEjffvutYmJiJEmrV6/Wp59+qqpVq+rgwYPatGmTihYt+to1dO/eXV999ZWOHTumSpUq6fHjxypUqJBWr16tI0eOqHXr1mrUqJH27NljWadHjx4aMmSIAgMDdfToUQUFBVmuENOyZUsFBQUpIiLC0n/evHnKkCGDypcv/x+fMQAA3g4mjgMAAKpdu3ac+zNmzFC6dOl09OhR7dq1Szdu3NDevXuVOnVqSVK2bNksfb///nvVq1dP/fr1s7Tly5fvtWvo1KmTatWqFaeta9euln936NBB69at06JFi1S0aFGFhYVp7NixGj9+vJo0aSJJypo1q0qVKiVJqlWrlgICArRy5UrVqVNHkjRr1iw1bdpUJpPptesDACAhcCQdAADo1KlTql+/vrJkySJXV1f5+PhIkkJDQxUSEqICBQpYAvrfhYSEqEKFCv+5hsKFC8e5Hx0drQEDBsjPz0+pU6eWi4uL1q1bp9DQUEnSsWPHFBER8dJ9Ozk5qVGjRpoxY4Yk6cCBAzpy5IiaNm36n2sFAOBt4Ug6AABQ9erVlTlzZk2dOlXp06dXTEyM3n//fUVGRsrZ2fkf1/235SaTSWazOU7biyaGS548eZz7w4cP19ixYzVmzBj5+fkpefLk6tSpkyIjI19pv9LTIe/58+fXxYsXNXPmTJUvX16ZM2f+1/UAALAWjqQDAJDE3bp1SydOnFCvXr1UoUIF5cqVS3fu3LEsz5s3r0JCQnT79u0Xrp83b95/nIgtXbp0unLliuX+qVOnFB4e/q917dy5U5988okaNmyofPnyKUuWLDp58qRlua+vr5ydnf9x335+fipcuLCmTp2qoKAgNW/e/F/3CwCANRHSAQBI4lKlSqU0adJoypQpOn36tDZv3qzOnTtbltevX1+enp6qWbOmdu7cqb/++ktLly7Vb7/9Jknq06ePfvrpJ/Xp00fHjh3T4cOHNXToUMv65cuX1/jx43Xw4EHt27dPbdu2lb29/b/W5evrqw0bNmjXrl06duyY2rRpo2vXrlmWOzk5qVu3bvr22281Z84cnTlzRrt379b06dPjbKdly5YaMmSIzGZznFnnAQAwIoa7AwDwlm2IWWztEv6RjY2NFixYoI4dO+r9999Xjhw5NG7cOJUtW1aS5ODgoPXr16tLly6qWrWqoqKilDt3bv3444+SpLJly2rx4sUaMGCAhgwZIldXV3344YeW7Y8cOVLNmjVT6dKllT59eo0dO1b79+//17p69eqlv/76S5UqVVKyZMnUunVr1axZU/fu3bP0CQwMlJ2dnXr37q3Lly/Ly8tLbdu2jbOd+vXrq1OnTqpfv76cnJzi4RkDAODtIaQDAAD5+/vr6NGjcdqePY88c+bMWrJkyUvXr1Wr1nMzs8dKnz691q1bF6ft7t27ln/7+Pg8d866JKVOnfq566v/nY2Njb777jt99913L+1z8+ZNPX78WC1atPjHbQEAYASEdAAA8E568uSJbt26pV69eumDDz5QwYIFrV0SAAD/inPSAQDAO2nnzp3y8vLS3r17NWnSJGuXAwDAK+FIOgAAeCeVLVv2hcPoAQAwMo6kAwAAAABgEIR0AAAAAAAMgpAOAAAAAIBBENIBAAAAADAIQjoAAAAAAAZBSAcAAAAAwCC4BBsAAG9ZwS9HJ+j+Dkz8OkH396aCg4NVrlw53blzRylTpoy3vgAAJGYcSQcAAFZRokQJXblyRW5ubvHaFwCAxIyQDgAAXltkZOR/3oaDg4M8PT1lMpnitS8AAIkZIR0AAKhs2bIKCAhQQECA3NzclDZtWgUGBspsNkuSfHx8NGDAADVu3Fiurq5q3bq1JGnHjh0qXbq0nJ2d5e3trY4dO+rhw4eW7UZERKhbt27y9vaWo6OjsmXLpunTp0t6OoTdZDLp7t27kqTz58+revXqSpUqlZInT648efJozZo1L+wrSUuXLlWePHnk6OgoHx8fjRw5Ms5j8vHx0aBBg9S8eXOlSJFCmTJl0pQpU97WUwgAQLwgpAMAAEnS7NmzZWdnpz179mjs2LEaNWqUpk2bZlk+YsQI5cuXTwcPHlRgYKDOnDmjypUrq3bt2vrjjz+0cOFC7dixQwEBAZZ1GjdurJ9++knjxo3TsWPHNHnyZLm4uLxw/+3bt1dERIS2bdumw4cPa+jQoS/tu3//ftWpU0f16tXT4cOH1bdvXwUGBmrWrFlx+o0cOVKFCxfWwYMH1a5dO3355Zc6ceLEf3+yAAB4S5g4DgAASJK8vb01evRomUwm5ciRQ4cPH9bo0aPVqlUrSVL58uXVpUsXS/+WLVuqQYMG6tSpkyTJ19dX48aNU5kyZTRx4kSFhoZq0aJF2rBhg/z9/SVJWbJkeen+Q0NDVbt2bfn5+f1r31GjRqlChQoKDAyUJGXPnl1Hjx7V8OHD1bRpU0u/qlWrql27dpKkbt26afTo0dqyZYty5Mjx+k8QAAAJgCPpAABAkvTBBx/EOee7ePHiOnXqlKKjoyVJhQsXjtP/0KFDmjVrllxcXCy3SpUqKSYmRmfPnlVISIhsbW1VpkyZV9p/x44dNXDgQJUsWVJ9+vTRH3/88dK+x44dU8mSJeO0lSxZMk69kpQ3b17Lv00mkzw9PXX9+vVXqgcAAGsgpAMAgFeSPHnyOPcfPHigNm3aKCQkxHI7dOiQTp06paxZs8rZ2fm1tt+yZUv99ddfatSokQ4fPqzChQvrhx9++E8129vbx7lvMpkUExPzn7YJAMDbREgHAACSpN9//z3O/d27d8vX11e2trYv7F+wYEEdPXpU2bJle+7m4OAgPz8/xcTEaOvWra9cg7e3t9q2batly5apS5cumjp16gv75cqVSzt37ozTtnPnTmXPnv2l9QIAkBgQ0gEAgKSn54R37txZJ06c0E8//aQffvhBX3311Uv7d+vWTbt27VJAQIBCQkJ06tQprVy50jJxnI+Pj5o0aaLmzZtrxYoVOnv2rIKDg7Vo0aIXbq9Tp05at26dzp49qwMHDmjLli3KlSvXC/t26dJFmzZt0oABA3Ty5EnNnj1b48ePV9euXf/7EwEAgBUxcRwAAG/ZgYlfW7uEV9K4cWM9evRIRYsWla2trb766ivLpdZeJG/evNq6dau+++47lS5dWmazWVmzZlXdunUtfSZOnKiePXuqXbt2unXrljJlyqSePXu+cHvR0dFq3769Ll68KFdXV1WuXFmjR49+Yd+CBQtq0aJF6t27twYMGCAvLy/1798/zqRxAAAkRoR0AAAg6en522PGjNHEiROfW3bu3LkXrlOkSBGtX7/+pdt0cnLSqFGjNGrUqOeWlS1b1nIddkn/eP753/tKUu3atVW7du2XrvOimkNCQl7aHwAAI2C4OwAAAAAABkFIBwAAAADAIBjuDgAAFBwcbO0SAACAOJIOAAAAAIBhENIBAAAAADAIQjoAAAAAAAZBSAcAAAAAwCAI6QAAAAAAGAQhHQAAAAAAg+ASbAAAvGVF1/ZM0P3tqTwoQff3pvr27asVK1YoJCREktS0aVPdvXtXK1assGpdAABYE0fSAQAAAAAwCEI6AAB4TmRkpLVLAAAgSSKkAwAAlS1bVgEBAerUqZPSpk2rSpUq6ciRI6pSpYpcXFzk4eGhRo0a6ebNm5Z1YmJiNGzYMGXLlk2Ojo7KlCmTvv/+e8vybt26KXv27EqWLJmyZMmiwMBAPXnyxBoPDwCARIOQDgAAJEmzZ8+Wg4ODdu7cqSFDhqh8+fIqUKCA9u3bp7Vr1+ratWuqU6eOpX+PHj00ZMgQBQYG6ujRowoKCpKHh4dleYoUKTRr1iwdPXpUY8eO1dSpUzV69GhrPDQAABINJo4DAACSJF9fXw0bNkySNHDgQBUoUECDBv1vEroZM2bI29tbJ0+elJeXl8aOHavx48erSZMmkqSsWbOqVKlSlv69evWy/NvHx0ddu3bVggUL9O233ybQIwIAIPEhpAMAAElSoUKFLP8+dOiQtmzZIhcXl+f6nTlzRnfv3lVERIQqVKjw0u0tXLhQ48aN05kzZ/TgwQNFRUXJ1dX1rdQOAMC7gpAOAAAkScmTJ7f8+8GDB6pevbqGDh36XD8vLy/99ddf/7it3377TQ0aNFC/fv1UqVIlubm5acGCBRo5cmS81w0AwLuEkA4AAJ5TsGBBLV26VD4+PrKze/7rgq+vr5ydnbVp0ya1bNnyueW7du1S5syZ9d1331nazp8//1ZrBgDgXcDEcQAA4Dnt27fX7du3Vb9+fe3du1dnzpzRunXr1KxZM0VHR8vJyUndunXTt99+qzlz5ujMmTPavXu3pk+fLulpiA8NDdWCBQt05swZjRs3TsuXL7fyowIAwPg4kg4AwFu2p/Kgf+9kMOnTp9fOnTvVrVs3VaxYUREREcqcObMqV64sG5unv/EHBgbKzs5OvXv31uXLl+Xl5aW2bdtKkmrUqKGvv/5aAQEBioiIULVq1RQYGKi+ffta8VEBAGB8hHQAAKDg4ODn2nx9fbVs2bKXrmNjY6PvvvsuzpD2Zw0bNswyW3ysTp06Wf7dt2/fOKF91qxZr1MyAADvJIa7AwAAAABgEIR0AAAAAAAMgpAOAAAAAIBBENIBAAAAADAIQjoAAAAAAAZBSAcAAAAAwCAI6QAAAAAAGAQhHQAAAAAAgyCkAwAAAABgEHbWLgAAgHddzNXsCbo/G8+Tr72O2WxWmzZttGTJEt25c0cHDx5U/vz54784AADwjziSDgAAtHbtWs2aNUu//PKLrly5ovv376t69epKnz69TCaTVqxYYe0SAQBIEgjpAABAZ86ckZeXl0qUKCFPT089fPhQ+fLl048//mjt0l4qMjLS2iUAABDvCOkAACRxTZs2VYcOHRQaGiqTySQfHx9VqVJFAwcO1KeffvrK2zGbzerbt68yZcokR0dHpU+fXh07drQsj4iIULdu3eTt7S1HR0dly5ZN06dPtyzfunWrihYtKkdHR3l5eal79+6KioqyLC9btqwCAgLUqVMnpU2bVpUqVZIkHTlyRFWqVJGLi4s8PDzUqFEj3bx5Mx6eGQAAEh4hHQCAJG7s2LHq37+/MmbMqCtXrmjv3r1vtJ2lS5dq9OjRmjx5sk6dOqUVK1bIz8/Psrxx48b66aefNG7cOB07dkyTJ0+Wi4uLJOnSpUuqWrWqihQpokOHDmnixImaPn26Bg4cGGcfs2fPloODg3bu3KlJkybp7t27Kl++vAoUKKB9+/Zp7dq1unbtmurUqfPmTwgAAFbExHEAACRxbm5uSpEihWxtbeXp6fnG2wkNDZWnp6f8/f1lb2+vTJkyqWjRopKkkydPatGiRdqwYYP8/f0lSVmyZLGsO2HCBHl7e2v8+PEymUzKmTOnLl++rG7duql3796ysXl6XMHX11fDhg2zrDdw4EAVKFBAgwYNsrTNmDFD3t7eOnnypLJnT9hJ+wAA+K84kg4AAF7boEGD5OLiYrmFhobq888/16NHj5QlSxa1atVKy5cvtwxXDwkJka2trcqUKfPC7R07dkzFixeXyWSytJUsWVIPHjzQxYsXLW2FChWKs96hQ4e0ZcuWOLXkzJlT0tPz7AEASGw4kg4AAF5b27Zt4wwpT58+vezs7HTixAlt3LhRGzZsULt27TR8+HBt3bpVzs7O8bLf5MmTx7n/4MEDVa9eXUOHDn2ur5eXV7zsEwCAhERIBwAAry116tRKnTr1c+3Ozs6qXr26qlevrvbt2ytnzpw6fPiw/Pz8FBMTo61bt1qGuz8rV65cWrp0qcxms+Vo+s6dO5UiRQplzJjxpXUULFhQS5culY+Pj+zs+FoDAEj8GO4OAACe8+DBA4WEhCgkJESSdPbsWYWEhCg0NPSl68yaNUvTp0/XkSNH9Ndff2nevHlydnZW5syZ5ePjoyZNmqh58+ZasWKFzp49q+DgYC1atEiS1K5dO124cEEdOnTQ8ePHtXLlSvXp00edO3e2nI/+Iu3bt9ft27dVv3597d27V2fOnNG6devUrFkzRUdHx+tzAgBAQuAnZwAA3jIbz5PWLuG17du3T+XKlbPc79y5sySpSZMmmjVr1gvXSZkypYYMGaLOnTsrOjpafn5++vnnn5UmTRpJ0sSJE9WzZ0+1a9dOt27dUqZMmdSzZ09JUoYMGbRmzRp98803ypcvn1KnTq0WLVqoV69e/1hn+vTptXPnTnXr1k0VK1ZURESEMmfOrMqVK/9juAcAwKgI6QAAQJ06dVKnTp0s98uWLSuz2fxa26hZs6Zq1qz50uVOTk4aNWqURo0a9cLlZcqU0Z49e166fnBw8AvbfX19tWzZstcpFQAAw+InZgAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHACCeve6EazCO2NeO1xAAYC2EdAAA4om9vb0kKTw83MqV4E3Fvnb3bz60ciUAgKSKS7ABABBPbG1tlTJlSl2/fl2SlCxZMplMJitXhVdhNpsVHh6u69evK2XKlIoMj7R2SQCAJIqQDgBAPPL09JQkS1BH4pIyZUrLawgAgDUQ0gEAiEcmk0leXl5yd3fXkydPrF0OXoO9vb1sbW2tXQYAIIkjpAMA8BbY2toS+AAAwGszxMRxP/74o3x8fOTk5KRixYppz549/9h/8eLFypkzp5ycnOTn56c1a9YkUKUAAAAAALw9Vg/pCxcuVOfOndWnTx8dOHBA+fLlU6VKlV56Lt+uXbtUv359tWjRQgcPHlTNmjVVs2ZNHTlyJIErBwAAAAAgfll9uPuoUaPUqlUrNWvWTJI0adIkrV69WjNmzFD37t2f6z927FhVrlxZ33zzjSRpwIAB2rBhg8aPH69JkyY91z8iIkIRERGW+/fu3ZMk3b9//208HEOJMif8uZDRkY8TfJ+SZHoY8e+d4tn9sOgE36dNsnf/fZuUJJXPKJ9PJEZJ5fMp8RlF4pRUPqN8Pt8dsfnTbDb/e2ezFUVERJhtbW3Ny5cvj9PeuHFjc40aNV64jre3t3n06NFx2nr37m3OmzfvC/v36dPHLIkbN27cuHHjxo0bN27cuHGz6u3ChQv/mpOteiT95s2bio6OloeHR5x2Dw8PHT9+/IXrXL169YX9r169+sL+PXr0UOfOnS33Y2JidPv2baVJk4Zr174j7t+/L29vb124cEGurq7WLgfAM/h8AsbGZxQwLj6f7xaz2aywsDClT5/+X/tafbj72+bo6ChHR8c4bSlTprROMXirXF1d+R8YYFB8PgFj4zMKGBefz3eHm5vbK/Wz6sRxadOmla2tra5duxan/dq1a/L09HzhOp6enq/VHwAAAACAxMKqId3BwUGFChXSpk2bLG0xMTHatGmTihcv/sJ1ihcvHqe/JG3YsOGl/QEAAAAASCysPty9c+fOatKkiQoXLqyiRYtqzJgxevjwoWW298aNGytDhgwaPHiwJOmrr75SmTJlNHLkSFWrVk0LFizQvn37NGXKFGs+DFiRo6Oj+vTp89xpDQCsj88nYGx8RgHj4vOZdJnM5leZA/7tGj9+vIYPH66rV68qf/78GjdunIoVKyZJKlu2rHx8fDRr1ixL/8WLF6tXr146d+6cfH19NWzYMFWtWtVK1QMAAAAAED8MEdIBAAAAAICVz0kHAAAAAAD/Q0gHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAOA/Yy5iAIgfhHQAgGFFR0dbuwQA/yI2nD948MDKlQB4mSdPnkiSYmJirFwJXgUhHXhDzx4x4H94QPwKCwuTJNna2mrfvn2KiIiwckUA/u706dPasmWLTCaTlixZolq1aunevXvWLgvA3yxYsEANGzbUzZs3ZWNjw/fWRICQDryi2FB+//59PXr0SCaTSevXr9fp06dlY8NHCYgvFy9eVNOmTbV+/XotXbpURYsW1YEDB6xdFoC/GTVqlCpUqKA+ffqoTp06aty4sdzc3KxdFoBnnDt3Tm3bttXPP/+sDh066Nq1awT1RIBkAbyGq1evys/PT1u3blVQUJAqV66so0ePWrss4J0SHh6u27dvq1u3bmrQoIFmz56t4sWL84UCMJgJEyaoWLFiGjJkiL755hs1atTI2iUB+BsnJyflyJFDfn5+MpvNat++va5fv05QNzhCOvCKTCaTPD09VaFCBdWtW1eNGjXSlClTVKNGDWuXBrwzzGazsmfPrhYtWujw4cPKkiWL0qRJI0l8oQAMInZkmdlsVlRUlHLlyqXJkydrw4YNVq4MwLPMZrM8PT319ddf6/r163rvvfd0+/ZttW/fXjdu3ODvqoER0oFXFDuBVUBAgMLCwuTg4CBPT089fvzYypUB7waz2SyTyaTo6Gj5+Pho0qRJypIli0aPHq3FixdLIqgD1hb7OT1y5IhCQ0O1d+9ehYSE6JNPPtFnn32m9evXx+l/8+ZNK1UKJF2RkZGS/jdnUokSJVSqVCmVLFlSLVq00IULFwjqBkdIB16B2WyWra2tHjx4oGzZsum3335T06ZNVa9ePa1cufKFQZ3/4QGvLvaL//r169WxY0flyZNHLVu21IgRI2Rra6vJkydr6dKlkp4G9dWrVzOZHJDAYj+ny5cvV40aNbRo0SKdP39ekjRz5kx98sknqlu3rtatW6eoqCgNHTpUjRo1UkREBJdnAxLIkiVLVLt2be3atcsykWOmTJmULFkyDR06VA0aNFBAQIAuX76sgIAAS1DnM2osJjOvCPCPYr+UrF27VkFBQWrTpo1KliwpSWrZsqUWLFigWbNm6eOPP5aTk5MmTZokf39/ZcuWzcqVA4nL0qVL1bJlS7Vo0UJ16tRR0aJFJUlHjx5V586dFR0drcqVKyssLEz9+/fX+fPn5e3tbeWqgaTl119/1eeff64hQ4aocePGcnV1jbO8SZMmmjt3rj788EPt3btX27dvV8GCBa1ULZC0nDhxQqVLl9bNmzfl6+ur0qVLy8fHR7169dLdu3fVoEEDNW/eXLVq1dK0adM0f/582draasmSJUqVKpW1y8czCOnAK1i2bJkaNmyoPn36qFq1anr//fcty5o1a6bly5erS5cuunbtmiZOnKjDhw8rd+7cVqwYSFwOHjyoihUr6vvvv1fr1q0t7bdv31bq1Kl19uxZ9erVSydOnFB4eLjmzZvHF38gAZnNZj169Eiff/658ubNq8GDB+vhw4e6fPmyfvnlF9nZ2alDhw6SpBkzZigsLExVq1aVr6+vlSsHko5bt25pwoQJ2rZtmyIiItSqVSuNGDFC7u7uypMnj86cOaM8efJoyJAhkqRx48bp+PHjGj9+PFcqMhhCOvAvjhw5oqpVq6pv375q3ry5pf3PP/9Unjx5JEkdO3bUwYMHFRERoSlTpih//vxWqhZInObPn69JkyZp+/btunPnjtauXat58+bp0KFDCggIUPfu3XX37l09fvxYdnZ2Sps2rbVLBpKkzz//XKlSpVKnTp00YcIEHT9+XGfOnFFERIQqVKiguXPnSvrfKDQACevatWuaOXOmFi9erKpVq2rAgAGaMWOGduzYoVmzZildunQ6evSoZVLW2M9qTEwMQd1A7KxdAGB0165dU/LkyVW/fn1FRUVp1qxZmj9/vo4dO6aiRYtq1apVGjdunK5fvy5nZ2elSJHC2iUDicKzX+K9vLy0c+dO9erVS8HBwUqdOrUyZcqkkiVLqmfPnqpUqZIKFChg5YoB5M6dW2vXrlXevHlVq1YttWjRQtWqVdOIESN0+PBhyxd9AjqQMA4dOqRLly4pderUypUrlzw8PNS8eXOZTCbNmDFDkjRgwAA1b95cNWvWVM6cOZUmTZo4n1Wz2UxANxhCOvAvUqZMKVtbWzVs2FBnzpxR5syZ5efnp65du6pGjRqaO3euGjVqJHd3d2uXCiQKseE8MjJSjo6OiomJUfny5TVixAjNmTNHH374oZo2bWoJ5StWrOAqCkACi/2cHj58WFeuXNHDhw9VrVo19evXT1988YUuXLggf39/S78rV67I0dFR0dHRfNkHEsiMGTM0cOBARUVFycnJSV988YW6desmd3d3tWzZUpI0e/ZshYWFacyYMZbLBv89lPOjmvEw3B14RuyXjRs3bigiIkLJkydXqlSp9NNPP2nNmjXy9vZWo0aNlCtXLj1+/FgVK1bUd999p0qVKlm7dCBReHYixvnz5+vKlSvKmzevmjVrJj8/P4WFhcUZjdKzZ08tWrRIO3bskKenpxUrB5KeJUuWqG3btsqYMaP++OMPFS1aVM2aNVObNm0sfUJDQzV+/HhNmzZN27dvt5wGBuDtmjJligICAjRz5kyVLVtWo0aN0q+//qqQkBA5ODhIejoadNasWZo3b54qVaqkESNGWLlqvCqOpAP/LzY8rFixQiNGjFBoaKhy5sypAgUKaOjQoapfv36cvoMHD9b58+eVK1cuK1YNJC4mk0mrVq1SnTp11L59e5lMJh09elQlS5bUqlWrVLZsWUnS+vXrtWDBAv38889av349AR1IYAcPHlTbtm01dOhQffrpp3r8+LG6d++uoKAgxcTE6Msvv9T69es1Y8YM/fnnn9q8eTMBHUgg06dPV0BAgBYvXqxPPvlEkhQQEKAdO3Zo6tSpevjwoT755BPlyJFDzZo1k42NjYYPH67MmTNbJniEsXEkHXjGunXr9Omnn2rIkCGqUKGCli9frt69e2vJkiWqVauWJGnVqlX6+eeftXLlSq1bt47zZIHXcP/+fVWvXl3+/v4KDAyU9PRI3Pfff6+FCxdq27Zt8vX11bx587Rp0yYFBgbyxR+wgnnz5mnIkCH67bff5OLiYhnS3qVLF12+fFlbtmyRyWTS6tWrlS9fPmXMmNHaJQNJwoMHD1SwYEE9efJEf/75p5IlSyZJqlq1qg4ePKjMmTPr9u3bOnfunHbv3q2CBQvq2rVr2rhxo+rVqydbW1srPwK8Ck4aAv5fdHS0lixZom+//VYdO3ZUunTpLEOJYgO6JN29e1eOjo7aunUrAR14TRERETpz5kycL/Te3t7q0aOHChcurOXLl8vZ2Vl16tTR9OnTCehAAos9dmNjY6OIiAiFh4fLZDIpKipKXl5eGjBggLZt26aNGzdKkqpVq0ZABxKQi4uLli9fLrPZrM8++0yPHz/W559/rtDQUG3dulXBwcFavny5cuTIoW7duunx48fy8PBQgwYNZGtrq+joaGs/BLwCQjqStNgvI7dv35atra0uXLggLy8vXblyRQULFlSVKlU0duxYSdKiRYu0efNmNW7cWMOHD2eYO/AaYj9r6dKlU/78+bVz5049ePBA0tMh8D4+PkqWLJkOHz4sSXJzc1Py5MmtVi+QVMVOIFWgQAGFhoZq4sSJkiQ7u6dnSNra2ipPnjxKmTKltUoEkqSoqChFRUVJkvLkyaNff/1Vf/zxh1KlSqVjx45pzZo1yp49u5ycnJQrVy7lyJFDrq6ucnJyirMdjqQnDoR0JGkmk0lLlixR69atdebMGWXNmlV79+5VyZIlVaVKFU2ePFkmk0n37t3TunXrFBISoujoaDk7O1u7dMDwYoN5TEyMYmJiLO1lypTR77//rp9++knh4eGWdldXV3l5eSk6OlqciQUkjNjP2pEjR7Rq1SqtW7dOFy9eVK5cuTR58mQNGjRIvXr10pkzZ3Tjxg1NmzZN9+/fV4YMGaxcOZB0rF27Vj169NBnn32m27dvy2w2K1euXNq4caOyZMkiNzc3ubm5WfpHRUXpzp07ypo1qxWrxn/BOelIkmInibt27ZrKlSunDh066Msvv1RwcLA++ugj5cyZU9u2bVOqVKlkNpvVq1cvBQUFaePGjfwPD3gFsZ+xdevWae7cubp06ZIKFCigVq1aKVeuXAoICNDWrVv1/vvvq0iRIjp+/LgWLFig3bt3K3fu3NYuH0hSlixZooCAAKVIkUJRUVG6e/euFixYoEqVKmnu3Ln68ssvlSZNGjk5Oenhw4datWqVChYsaO2ygSRh5syZGjhwoNq3by83Nze1aNFCkvT48WM5OTnp2LFj8vf3V548ebRo0SKlTJlS1apV04ULF3TgwAHZ2dlZ/iYj8SCkI8lav369du3apfPnz2vs2LFydXWV9HRYe/369VW9enXZ2NjIyclJa9eu1aZNmzgHHXgNq1at0ueff65GjRrJ1dVVy5cvV8aMGdWjRw9VrVpV48aN0/bt23Xs2DG99957+v7775U3b15rlw0kKQcOHFD58uU1YsQI1ahRQ7dv39bYsWM1e/ZsrVq1Sv7+/jp9+rROnTql6Oho5cuXT97e3tYuG0gSFixYoObNm2vOnDn69NNPLUPVv/vuO2XLlk1169ZVsmTJdOzYMVWsWFHvv/++oqKidOHCBR0+fFj29vaKjo5miHsiREhHkjVs2DB1795dXl5e+v3335UxY0bLL41bt27V8uXLdenSJfn5+alu3brKkSOHtUsGEgWz2aw7d+6oWrVqqlmzprp16ybp6fVaW7Vqpdu3b2vOnDnKkiWLJCksLEwODg5ydHS0ZtlAkrRkyRKNGDFCmzdvtswSHRMTo7Zt2+rnn3/WgQMH5OXlZeUqgaTn0qVL+uyzz1SrVi198803lvYaNWrol19+UbJkyTRx4kR99tlncnZ21rFjx1SyZEmlTp1ax44dk729vaKioizzSSBx4Zx0JFnffvutJkyYoCtXrmj+/PmKiYmRyWSS2WxWmTJlNGrUKC1evFi9e/cmoAOvwWQyycnJSQ8ePFCqVKkkSU+ePJGHh4emTZumc+fOaebMmZb+KVKkIKADVvLgwQMdOnTIMiFVdHS0bGxs1Lp1a9nb2+v8+fNWrhBImm7duqXz58+rVKlSlrb58+fr+PHjCgsLU8uWLdW2bVstXLhQDx8+VK5cuRQSEqITJ04Q0N8BvHJIEmKPkN+7d0+PHj2Sp6enzGaz2rZtq7t376pnz55ycXFR+/btLefscO4O8GrCwsJ09+5dpUuXzjKLbFRUlGJiYnTq1ClJT2eTffLkidzd3eXv768TJ05Ys2QgyTlz5ozmzZun+/fvq3jx4vrss88kPZ3IMU+ePOrfv7969uyp1KlTS3p6JQYHBwdFRERYs2wgybp8+bLu3r2rtGnTWtqqV6+uypUrK3ny5BozZowePnyotm3bqlixYsqVK5cyZcok6emPbQT0xI0j6XjnxQb0lStXqkqVKipSpIjKlSun77//XuHh4erevbsGDhyojh07Wi41IxHSgVfx559/qlq1aqpYsaIKFSqkDRs2SHo6U3vPnj01atQozZgxQzY2NrK3t5ck3blzRx4eHtYsG0hSDh06pNKlS2v79u3au3evGjVqpCVLlkiSfHx8VLVqVf3222/q37+/rl+/rhs3bmjq1KmKiYlR9uzZrVw9kHQ8ew3z1KlT6/Hjx9q9e7ekp99nXV1dlSZNGsvIl7p166pkyZKWU1VicQ564sdPLHinxU6WsX79etWtW1ffffedcubMqXXr1unnn3/WqVOnNGnSJPXo0UP29vZq37697O3t1bJlS2uXDhhe7Bf/xo0b6+OPP9aIESPUsWNHHT16VCaTSZ9++ql69uypli1b6sCBA/L29tbFixe1efNm/f7779YuH0gS/vjjDxUvXlydOnXSgAEDdOPGDbVo0UIXL15UTEyMbGxs1LdvXzk7O2vp0qXy8vJSvnz5dPXqVf3yyy+cjw4kkIiICMupXwcPHlShQoX0ySefqEuXLipYsKDy5Mlj+V5rZ2enR48eacyYMcqUKZPlCDreHUwch3dK7BeOW7duKU2aNJKkyMhItWzZUqlSpdLYsWMlPR2KO336dE2bNk316tVTly5dJEk//PCD/P39lStXLqs9BiAxOHz4sD744AN988036tu3ryTp+PHjatOmjUaMGCEnJydlypRJbm5uWrBggUaNGiU7Ozu5urpq2LBhzOIOJIC//vpLhQoV0meffaapU6da2j/++GNFRkbqwYMH8vPzU7t27ZQvXz7dvHlT27Ztk5ubm7Jnz84s7kAC2bhxo0aNGqU1a9aoU6dO2rlzpzZs2KCQkBC1b99eN27c0MKFC1WkSBG5uLgoJCRE3bp10+XLl3Xw4EEus/YOIqTjnREb0A8dOqRatWrpp59+UtGiRSU9nQnTxcVFQUFBlv5ms1kNGjTQ7du3tXbtWmuVDSQ69+/fl7+/v65evarQ0FBL+7fffqsffvhBXl5eevjwobJly6Y5c+Yoa9asCg8Pl7Ozsx49evTcsDwAb8f8+fPVpUsXNWjQQF9++aWyZcumwYMHq3///mrbtq2SJUum8ePHK2/evFq5cqXlfHQACScmJkZz587VhAkTFBYWpqtXr2rPnj3Kli2bzGaz1q1bp8GDB2v79u3KkSOHIiMjlSJFCqVMmVIbNmzgMmvvKM5Jxzvh2YD+wQcfqF69eipatKjMZrOio6OVJUsWhYaG6vLly4qJiZH09JzzsmXL6tKlS7p3756VHwGQuDRr1sxymSZJGjlypKZMmaKZM2dq69atGjBggC5fvqxx48ZZhvCZTCY5OztbuXLg3Rd7/KVBgwbq37+/Nm3apKlTp6pLly4aPXq0Vq5cqdGjR+v777/XqlWrtHPnTu3atcvKVQNJk42NjZo0aSIfHx8dP35cBQoUULZs2SQ9/a5auXJl/fLLL5o2bZpq166tBg0aaODAgdq0aZNlFncC+ruHI+lI9GIDeuzw2y5duqh///5x+ly6dEl58+ZVxYoVNXz4cGXMmFGS1KZNG50/f14rVqywzEoN4N/du3dPy5YtU7du3ZQ+fXpdvnxZixcvVpkyZSx9PvzwQ6VMmVKrVq2yYqVA0hUaGqpMmTJp0qRJGjdunM6dO6cff/zR8iOb9PSc9Tp16mj69OkqXbq0lSsGko7Y4enR0dGKjIzUnDlzdOfOHa1evVqpU6fWvHnzlCJFCj158sQy8erfcQT93cWRdCR6NjY2On/+vPLly6d69erFCehDhw5Vv379lCFDBm3cuFEbNmzQ559/ripVqqh+/fr66aefNHToUAI68C8uXryo+fPnq1evXgoLC5Obm5vq1KmjYcOGKSwsTPnz57cE9NhLNmXIkEE+Pj6KiooSvwcDb9/Zs2ctl1ZbuXKlKlasqL/++ktt27ZVly5dlDVrVoWEhOjkyZOysbGRjY2Nli5dKnt7e/n6+lq5eiDpiI6Otpw/HhMTIycnJ7Vp00bdu3dXixYtdO3aNTVs2FAPHjywBPStW7fq4cOHcbZDQH93EdLxTkibNq3c3d118uRJ/fHHH5KkESNGqG/fvipRooQkqUCBAjp06JA++ugjubu7y93dXb///rvy5ctnzdIBwzty5Ig++eQTbd26VTExMUqRIoUkKXny5Prkk08UGBioP/74Q61bt5YkOTo6KjAwUBs2bFC7du1kZ2fHZDZAAjhx4oR2796tIkWK6NNPP1WfPn2UJUsWSVKLFi3Utm1bbd++XWPHjtXly5c1ePBgjRgxQvPnz5enp6eVqwfefbGnlcSG68GDB+vjjz9WxYoVtWjRIklPT1Np166dbty4oc8++0zHjh1TpUqVNGTIEOZ0SUIY7o5EL3aoT1hYmAoUKCAvLy8VLlxYc+fO1aJFi1S+fPk4/Z4dXsQvkMA/O3r0qEqWLKmAgAB16tTJctWEoKAgFS5cWNmzZ9e9e/e0fPlyde/eXXXr1lX69OnVt29f7dy5UwULFrTyIwCSlt69e2vgwIHy8/PToUOHJMW9tNOECRM0e/ZshYWF6ezZs9qxY4cKFSpkzZKBJGHu3Llq0qSJFixYoDp16mjw4MEaPXq0GjdurNDQUC1ZskRDhw7VN998oydPnmj58uUaNWqUQkNDlSVLFm3ZsuWlw97x7iGk450QG7jv37+vDz74QMePH9fEiRPVpk2b5/rGhnQuVQH8szt37uiTTz5Rzpw5NWXKFEv7kCFD1LNnT6VOnVo7duxQzpw5de/ePa1cuVLt2rVTeHi49u7dyxd/IAHFzs8ya9YsHT16VGvWrJGXl5c2bNggSXr06JFl4sYJEyZo4sSJCgoKkp+fnzXLBpKM+/fva9CgQRo5cqQWLFigc+fOKX/+/KpQoYKioqI0ceJEderUSYMHD9a3336rmJgY3b9/X6dOnVKhQoVkY2OjqKgo2dnZWfuhIAEQ0pFoxYbsiIgIOTg4WAL3gwcPVKhQIaVKlUqTJk1S/vz5rVsokEgdOnRIDRo00A8//KBy5cpJkpYuXaoWLVpo/PjxWrx4sXbv3q3g4GDlypVLd+7c0dq1a1W0aFFlzZrVytUDSVd0dLTWrFmjb775Rt7e3pagLj39XOfLl09hYWGWU1cAJIwHDx5owIABGjFihNKmTaugoCBVqFDBsnz8+PGWoP7NN9/EWZcRoEkL56QjUYoN6KtXr1azZs1Uo0YNbd26VTdv3pSLi4v27t2rGzduqFWrVpbhfgBeTWRkpCTp2LFjCg0NjRO4PTw8tH37djVs2FBTpkxR0aJFVahQIV29elWpUqVSvXr1COhAAok9zrJ//35NnTpV06dP17Fjx2Rrayt/f3+NGDFCFy9eVIUKFXT9+nUFBgaqQYMGunnzJgEdSCCxV1KQJBcXF/Xq1Uv9+vXTjRs3dOLECUn/+ywHBARo3Lhx6tatm4KCguJsh4CetBDSkSiZTCbt2LFD9erVU/LkyXX37l3Vrl1bM2fO1MWLF+Xq6qqDBw8qLCxMn332mY4cOWLtkoFE4dSpUxo4cKCkp18mHjx4oNDQUMvyUqVKWYbHenh4qH79+sqRI4eio6MliVNIgAQS+2P1smXLVKNGDU2ePFlz5szRhx9+qB07dsjZ2Vn+/v4aM2aMLl26pAIFCmjWrFmaOXOm0qZNa+3ygSTBbDbLxuZp3AoKCtL169eVIkUKdezYUd26dVOHDh20cOHCOH8727VrpyVLlqhOnTrWKhsGQEhHonXx4kV9++23mjp1qrZv36727dtr/PjxmjdvniWo//7770qRIoWSJ09u7XKBRGHu3LmaN2+eJKlkyZIqWLCgOnbsaAnqsUfZY48M7N27V1myZJGbm5t1CgaSKJPJpK1bt6pNmzbq27ev9u3bp5EjR+rWrVuqWLGi1qxZIycnJ/n7+2vXrl2aMWOGfvvtNxUpUsTapQNJQkxMjCV8X716VQ0bNlTHjh118+ZNubq66rvvvlPXrl31xRdfaOHChZL+d0S9Vq1asrOzU1RUlNXqh3Ux8wASjdijBgcPHtTFixd14MABvffee5bl/fr1k/R0QhxbW1vVrVtXmTJl0v79+zm6B/yL2M9XiRIltGTJEkVERChVqlRq1KiRhg8frhYtWmjmzJnKmDGjpKeTyo0YMUKzZ8/W9u3b5eLiYuVHALz7bty4ofPnz0uSChcurC1btqhdu3Zq1aqVLl26pNq1a6tp06aKjo5WrVq1tHbtWpUtW1apU6dWpUqVrFw9kHQ8ewS9d+/eun79urJkyaJFixbpwYMHmj17ttKkSaPAwECZTCY1atRI4eHhatasWZztMElc0sXEcUhUli1bpgYNGihTpkw6deqU/P39NXXqVGXOnNnSp3///ho2bJgGDhyoDh06yMbGhpAOvKITJ06oQIECWrlypT766CNJTz9TU6dOVVhYmJo3b67r16/r/v372r9/v3755RcVKFDAylUD776jR4+qdevWSpEihZydnbVs2TLt379fkZGRev/99/XRRx8pX758mjx5snbu3KnSpUtLktavXy9/f38rVw8kTSNGjNCgQYO0cuVKOTk56eLFi/ryyy9VoEABzZs3T2nSpNGDBw/0zTff6MiRI9q+fbu1S4ZB8PMMEo1Lly5p2bJlGjt2rD7//HNNnjxZ8+bN0w8//KAOHTpYgnrv3r3l4OCgatWqMckG8C/OnTunzZs3q1y5cnJ2dtZ7770nX19fPXr0yNKnd+/eKlKkiFasWKFt27bJ2dlZ5cuX16hRo5QtWzYrVg8kDX/++adKlSqldu3aqU2bNsqQIYMkWS5zuGfPHkVHR+vrr7+WJKVMmVKff/65MmfObOkL4O3atm2bSpQoYTn6bTabdeDAATVs2NDyo1mRIkXk7e2tKlWqqFWrVpo8ebLSpUunkSNHysnJyZrlw2AI6UgUDhw4oIEDB+rhw4eqVq2aUqVKpe7du8vOzk7z58+3fDnJlCmTJKl79+5WrhgwvsjISHXo0EEHDhyQjY2NHj9+rIoVK+rw4cOaOXOmcufOLVtbW7333nuqUqWKqlSpoidPnsje3t4yPB7A23X79m21bdtWjRs31vfff29pj70uuiTdunVL+/fvt5y/umDBAj148EB9+/ZVsmTJrFI3kJT07dtXGzZs0I4dOyxtMTExunTpkh4/fmxpi46OVuHChdWuXTsNGDBAtra2+umnn5QsWTKZzWb+tsKCkI5EYe/evTp58qSuXLmi8PBwS3vXrl0lSYsWLdLDhw8VGBgob29va5UJJCoODg4KCgpSihQpdPDgQR0/flwXL15USEiIVq5cqX379ikqKkp58uRR+vTpVbRoURUvXtxy9A7A23f16lVduXJFtWvXjhPMY/9rNpvl7++vmjVrKm/evCpcuLCOHTumHTt2ENCBBNK3b1/16tVLJpNJJ06cUObMmeXk5KS2bdvqm2++UVBQkL744gvLCM+MGTOqcePG+vXXX9W+fXtNnjyZcI44OCcdica8efM0dOhQZcmSRSNHjowzzHbAgAHauHGjFi1aJA8PDytWCSQuL/rVfvjw4frjjz/UpUsX3bhxQ8HBwTp48KDu3LmjOXPmyNfX10rVAklPUFCQmjRposjISJlMpjhBPVZ4eLi2bNmiJ0+e6OzZs/r444/5nAIJJPYzaTabtXLlStWqVUuLFy9WzZo1dfnyZfXp00cnT55U69at1bhxY928eVPNmzfXRx99pOTJkyswMFBbtmxR9uzZrf1QYCCEdBhObGgIDQ1VdHS0Hj58qPfff1+SNGvWLM2YMUPp06fXoEGDlCVLFst6t2/fVurUqa1VNvDOWLx4sVq3bq0jR47EOZ/14cOHXM4QSGC7du1ShQoVNG/ePNWuXfuFfSZMmKAVK1Zo/fr1CVwdgL+rV6+eNmzYoGnTpunTTz/VkSNH9OOPP+qnn36yfE9Nnjy5Dh8+rFWrVqlz587auXMnB5kQB9dJh6HEBvRly5apUqVKKlOmjCpVqqTGjRvr7t27atq0qZo2barLly+rd+/eOnXqlGVdAjrw35nNZvn5+SlFihSW8+iio6MliaGzgBVkzpxZrq6umjNnjuXya9L/rqcsSWfOnFHBggXFcRcg4dy6dSvO/WfnhKhcubKaNGmi5cuX6/3339ewYcO0bds2BQQEaODAgTp48KAkafPmzfL29pajo2OC1w9j40g6DCc4OFhVq1bVmDFjlCVLFoWHh6tly5by8/PTypUr5eLiounTp2vcuHEqXLiwJk2aJHt7e2uXDbxTcubMqa5du6ply5bWLgVI8pYtW6YvvvhCderUUffu3ZU7d25JT4e5Dxw4UEFBQVq/fj3DZYEEsn37dvXu3Vv9+vXThx9+aGmPjo62nHfeoEED/fzzz5o9e7aqVKkSZ/b2EydOaMKECZo9e7a2bdumvHnzJvhjgLExcRys6q+//pK3t3eckB0cHCx/f3+1bt3a0rZv3z4VLFhQnTp10rRp09SiRQs5OjqqdOnSBHQgHsWOZnF2dtbZs2etXQ4ASTVr1tTYsWMVEBCgvXv3qnjx4nJyctKlS5e0e/durV27loAOJCB3d3eZzWYNGzZMtra2KlmypCTJ1tbWEtTnz5+vhg0bqlWrVvrhhx9Uu3ZtOTg46MmTJ9q2bZsuXbpEQMdLcSQdVrN48WLVq1dPP//8sypWrCg7OzuZzWY1btxYoaGh2rp1qyQpIiJCjo6OCgoKUmBgoDZs2BDnXHQA8W/ixIkqXbq0ZT4IANa3Z88eDR8+XKdPn1aKFClUokQJtWjRgkniACs4deqUOnbsKLPZrMDAQEtQN5vNiomJsRxRz5w5swoXLqylS5da1n3y5IkePXokV1dXq9QO4yOkw6qqVaumgwcPavr06apQoYIcHBy0cuVKtWjRQlOmTFGtWrUsfZctW6bu3btrx44dcnd3t2LVwLuPa7UCxvTscFoA1vVsUO/Vq5dKlSplWXbx4kW1a9dOfn5+6t+/v+Vzy99XvAomjoNVREZGSpJWr16tokWLqmXLltq4caMiIyNVuHBhVa1aVWPHjtWyZcskPZ2MY9++fUqZMiXD24EEwBcIwJievfwax1kA6/L19dW4ceNkMpk0cOBA7dy5U5J07do1NWjQQIcPH1bfvn0tw+Al/r7i1XAkHVYR+yvi4cOHdfXqVVWpUkXZs2fXqFGjVLlyZe3fv18//PCDVq5cqffee08uLi46cuSINm3apAIFCli7fAAAAEDS/46om0wmffnll/rhhx908eJFHTp0SPb29oqKipKdHVOB4dUR0mE1K1eu1Oeff67AwEBdvnxZ+/btU2hoqGbPnq3KlSvr2rVrOnLkiNasWaNMmTKpatWqnHcHAAAAwzl16pQ6deqkX3/9VTlz5iSg4z8hpMMq7t+/r3LlyqlKlSoaOHCgJCkmJkYff/yx9u/fr9mzZ6tcuXJcNxIAAACJwvHjxzVhwgSNGjVKdnZ2BHS8Mc5Jh1XY2toqKipKmTJlkvR0lksbGxutWrVKXl5e6tGjh9auXasnT55YuVIAAADg3+XMmVPjxo0joOM/I6TDKpInTy43NzetXLlSkmRvb68nT57Izs5OefLk0aFDh9S9e3fLBHMAAABAYkFAx39BSMdbF3tGxc2bNxUWFqaoqChJUmBgoI4dO6aOHTtKkmXWdk9PT+3atUsbNmxQ8uTJrVM0AAAAAFgB56QjQaxYsUJDhw7V9evXVbduXdWpU0f58+fXjz/+qOHDh8vX11f+/v46duyYFi1apKNHj8rHx8faZQMAAABAgiKk4607ePCg/P391aVLF92/f18bN25UhgwZ1KNHD33wwQfatm2bvv/+ez169Ej29vYaNWqU8uXLZ+2yAQAAACDBEdLxVp0+fVoLFiyQ2WxWYGCgJGnDhg0aOnSonJyc9O233+rDDz+U9HTyuOjoaDk5OVmzZAAAAACwGs5Jx1tz+fJl1a9fX2PHjtXdu3ct7R999JG6deumR48eafTo0Vq9erWkp+ekE9ABAAAAJGWEdLw16dOn19dffy13d3ft3LlTBw8etCz76KOP1LNnT128eFHz5s1TeHi4FSsFAAAAAGNguDveugULFmjYsGHKnz+/vvrqqzjnmwcHBytLliyW66UDAAAAQFJGSEe8MJvNMplM2rdvnw4dOqSoqCiVKFFCfn5+kqQ5c+Zo3Lhx8vPz09dff628efNauWIAAAAAMB5COv6z2IC+bNkytWzZUoUKFdLp06fl6+urmjVrql27dpKeBvUJEyYoY8aM6tu3r95//30rVw4AAAAAxmJn7QKQ+JlMJm3btk3t27fX0KFD1apVK/3++++qUKGCrl27pvDwcHXt2lWNGzdWRESEgoKClDp1amuXDQAAAACGw5F0vJaYmBjZ2Ng81zZo0CBdvnxZEyZM0NmzZ+Xv768iRYrIZDJp9+7d6tq1q9q3by9Junfvntzc3KxRPgAAAAAYGiEdryw2oF+4cEHr169XTEyMcuXKpVKlSuny5cu6du2acuTIIX9/f+XMmVMzZszQ8ePHVaJECbm6uuqrr77S119/bRkeDwAAAACIi+HueCWxAf2PP/5QjRo15OHhoTNnzihlypQaOnSoateurfTp02vXrl0KCwvTt99+K0mKjIxU4cKF5efnp9q1a0sSAR0AAAAAXoLrpONfPRvQixcvrvr162vLli1asGCBHj9+rJkzZ1qucx4TE6O7d+/qwIEDkqQlS5bI3d1dgYGBXGYNAAAAAP4Fw93xSi5cuKCCBQuqXLlyWrRokaW9aNGiunfvnvbs2SM3NzeFhYWpcePGOnr0qMxms27evKnNmzcrf/781iseAAAAABIJhrvjlURHR+u9995TRESEdu7cqZIlS2rw4MHat2+fihQpokaNGil16tSqVKmSvvrqK50/f15RUVH68MMP5evra+3yAQAAACBR4Eg6XtmpU6fUsWNHOTg4yN3dXStXrtSECRNUtGhRHThwQEeOHNG4cePk6uqqfPnyaenSpdYuGQAAAAASFUI6XsvJkycVEBCg7du3a8CAAeratWuc5bdu3bIMb+cIOgAAAAC8HkI6XtuZM2fUrl072draqmfPnipVqpQk6cmTJ7K3t7dydQAAAACQeDG7O15b1qxZNX78eJnNZg0cOFA7d+6UJAI6AAAAAPxHhHS8EV9fX40bN0729vbq2rWrdu/ebe2SAAAAACDRI6Tjjfn6+mr48OHKmDGj0qdPb+1yAAAAACDR45x0/GeRkZFycHCwdhkAAAAAkOgR0gEAAAAAMAiGuwMAAAAAYBCEdAAAAAAADIKQDgAAAACAQRDSAQAAAAAwCEI6AAAAAAAGQUgHAAAAAMAgCOkAAAAAABgEIR0AAAAAAIMgpAMAAAAAYBD/Byymhjlw2E9PAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = evaluate_models(models, pipeline, X_train, X_test, y_train, y_test)\n",
    "plot_model_performance(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"XGBoost\"] = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "models[\"LightGBM\"] = LGBMClassifier(min_data_in_leaf=10, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Ensemble Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85        36\n",
      "           1       0.96      0.96      0.96       167\n",
      "           2       0.89      0.81      0.85        21\n",
      "\n",
      "    accuracy                           0.93       224\n",
      "   macro avg       0.89      0.89      0.89       224\n",
      "weighted avg       0.93      0.93      0.93       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define base estimators with tuned hyperparameters (adjust as needed)\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=269, max_depth=11, \n",
    "                                   max_features=None, min_samples_leaf=3, \n",
    "                                   min_samples_split=3, random_state=42)),\n",
    "    ('xgb', XGBClassifier(eval_metric='mlogloss', random_state=42)),\n",
    "    ('cat', CatBoostClassifier(verbose=0, random_state=42)),\n",
    "    ('lgbm', LGBMClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "# Create the StackingClassifier with Logistic Regression as the final estimator.\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(max_iter=500, random_state=42),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train and evaluate the stacking ensemble.\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "y_pred_stacking = stacking_clf.predict(X_test)\n",
    "\n",
    "print(\"Stacking Ensemble Performance:\")\n",
    "print(classification_report(y_test, y_pred_stacking))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in the stacking model: 4\n"
     ]
    }
   ],
   "source": [
    "# Get the number of features in the stacking model\n",
    "n_features_stack = len(estimators)\n",
    "\n",
    "print(f\"Number of features in the stacking model: {n_features_stack}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Ensemble Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84        36\n",
      "           1       0.96      0.94      0.95       167\n",
      "           2       0.81      0.81      0.81        21\n",
      "\n",
      "    accuracy                           0.92       224\n",
      "   macro avg       0.86      0.88      0.87       224\n",
      "weighted avg       0.92      0.92      0.92       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define base estimators (using same tuned models as above)\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=269, max_depth=11, \n",
    "                                   max_features=None, min_samples_leaf=3, \n",
    "                                   min_samples_split=3, random_state=42)),\n",
    "    ('xgb', XGBClassifier(eval_metric='mlogloss', random_state=42)),\n",
    "    ('cat', CatBoostClassifier(verbose=0, random_state=42)),\n",
    "    ('lgbm', LGBMClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "# Create the VotingClassifier with soft voting.\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=estimators,\n",
    "    voting='soft',  # 'soft' voting averages probabilities\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train and evaluate the voting ensemble.\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred_voting = voting_clf.predict(X_test)\n",
    "\n",
    "print(\"Voting Ensemble Performance:\")\n",
    "print(classification_report(y_test, y_pred_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 625\n",
      "[LightGBM] [Info] Number of data points in the train set: 894, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score -1.805273\n",
      "[LightGBM] [Info] Start training from score -0.321815\n",
      "[LightGBM] [Info] Start training from score -2.200586\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Blended Ensemble Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84        36\n",
      "           1       0.96      0.94      0.95       167\n",
      "           2       0.81      0.81      0.81        21\n",
      "\n",
      "    accuracy                           0.92       224\n",
      "   macro avg       0.86      0.88      0.87       224\n",
      "weighted avg       0.92      0.92      0.92       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def blend_ensemble(models, X, weights):\n",
    "    \"\"\"\n",
    "    models: list of trained models that implement predict_proba\n",
    "    weights: list of weights (should sum to 1)\n",
    "    Returns the blended class predictions.\n",
    "    \"\"\"\n",
    "    # Initialize an array for blended probabilities\n",
    "    blended_prob = None\n",
    "    for model, weight in zip(models, weights):\n",
    "        prob = model.predict_proba(X)\n",
    "        if blended_prob is None:\n",
    "            blended_prob = weight * prob\n",
    "        else:\n",
    "            blended_prob += weight * prob\n",
    "    # Choose the class with the highest probability for each sample\n",
    "    return np.argmax(blended_prob, axis=1)\n",
    "\n",
    "# Assume you have individually tuned and trained models:\n",
    "rf_model = RandomForestClassifier(n_estimators=269, max_depth=11, \n",
    "                                  max_features=None, min_samples_leaf=3, \n",
    "                                  min_samples_split=3, random_state=42).fit(X_train, y_train)\n",
    "xgb_model = XGBClassifier(eval_metric='mlogloss', random_state=42).fit(X_train, y_train)\n",
    "cat_model = CatBoostClassifier(verbose=0, random_state=42).fit(X_train, y_train)\n",
    "lgbm_model = LGBMClassifier(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "# List of models and equal weights for blending\n",
    "models_list = [rf_model, xgb_model, cat_model, lgbm_model]\n",
    "weights = [0.25, 0.25, 0.25, 0.25]\n",
    "\n",
    "# Compute blended predictions\n",
    "y_pred_blend = blend_ensemble(models_list, X_test, weights)\n",
    "\n",
    "print(\"Blended Ensemble Performance:\")\n",
    "print(classification_report(y_test, y_pred_blend))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final stacking model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained stacking model\n",
    "joblib.dump(stacking_clf, r\"E:\\My_Projects\\Data_Science_Projects\\Employee Performance_Analysis\\src\\models\\final_model_stacking.pkl\")\n",
    "\n",
    "print(\"Final stacking model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\My_Projects\\\\Data_Science_Projects\\\\Employee Performance_Analysis\\\\src\\\\models\\\\voting_clf.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(blend_ensemble, r\"E:\\My_Projects\\Data_Science_Projects\\Employee Performance_Analysis\\src\\models\\blend_ensemble.pkl\")\n",
    "joblib.dump(voting_clf, r\"E:\\My_Projects\\Data_Science_Projects\\Employee Performance_Analysis\\src\\models\\voting_clf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory path\n",
    "directory = r\"E:\\My_Projects\\Data_Science_Projects\\Employee Performance_Analysis\\Data\"\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Now, save the files\n",
    "X_test.to_csv(f\"{directory}/X_test.csv\", index=False)\n",
    "y_test.to_csv(f\"{directory}/y_test.csv\", index=False)\n",
    "\n",
    "print(\"Test data saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 Important Features for rf:\n",
      "                       Feature  Importance\n",
      "8   EmpEnvironmentSatisfaction    0.245770\n",
      "15    EmpLastSalaryHikePercent    0.244717\n",
      "22     YearsSinceLastPromotion    0.201860\n",
      "\n",
      "Top 3 Important Features for xgb:\n",
      "                       Feature  Importance\n",
      "8   EmpEnvironmentSatisfaction    0.170982\n",
      "15    EmpLastSalaryHikePercent    0.138122\n",
      "22     YearsSinceLastPromotion    0.135999\n",
      "\n",
      "Top 3 Important Features for cat:\n",
      "                       Feature  Importance\n",
      "8   EmpEnvironmentSatisfaction   25.769009\n",
      "15    EmpLastSalaryHikePercent   19.319589\n",
      "22     YearsSinceLastPromotion   13.591655\n",
      "\n",
      "Top 3 Important Features for lgbm:\n",
      "               Feature  Importance\n",
      "9        EmpHourlyRate         974\n",
      "43    Mahalanobis_Dist         874\n",
      "19  EmpWorkLifeBalance         854\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Fit the stacking model (already done in your case)\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Extract base model feature importances\n",
    "base_model_importances = {}\n",
    "\n",
    "# Loop over base estimators in the stacking model\n",
    "for name, model in stacking_clf.named_estimators_.items():\n",
    "    if hasattr(model, 'feature_importances_'):  # Check if the model has feature importances\n",
    "        base_model_importances[name] = model.feature_importances_\n",
    "\n",
    "# Check if I have feature importances for any base model\n",
    "if base_model_importances:\n",
    "    for model_name, feature_importances in base_model_importances.items():\n",
    "        # Ensure feature names match the data used for training\n",
    "        if hasattr(stacking_clf, 'named_steps'):\n",
    "            preprocessor = stacking_clf.named_steps['preprocessor']  # Assuming you have a preprocessor\n",
    "            feature_names = preprocessor.get_feature_names_out()\n",
    "        else:\n",
    "            feature_names = X_train.columns  # Ensure this is the same data used for training\n",
    "\n",
    "        # Ensure lengths match\n",
    "        if len(feature_importances) == len(feature_names):\n",
    "            fi_df = pd.DataFrame({\n",
    "                'Feature': feature_names,\n",
    "                'Importance': feature_importances\n",
    "            }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "            print(f\"\\nTop 3 Important Features for {model_name}:\")\n",
    "            print(fi_df.head(3))\n",
    "        else:\n",
    "            print(f\"Mismatch detected in feature importances for {model_name}. Check preprocessing steps.\")\n",
    "else:\n",
    "    print(\"No feature importances found for base models in the stacking ensemble.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
