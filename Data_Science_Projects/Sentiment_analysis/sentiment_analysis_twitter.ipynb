{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The emotion behind written text can be considered vital information. As organizations are enabled with powerful tools to analyze data on a large scale, _Sentiment detection_ or _opinion mining_ can be of significance to gain inferences and insights.\n",
    "This may refer to a product, an event, or a subject of contention.\n",
    "Emotion can be categorized as:\n",
    "- Positive\n",
    "- Negative\n",
    "- Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /usr/local/lib/python3.10/dist-packages (4.13.0)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (2.31.0)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # regular expression / regex\n",
    "import tweepy #Collect tweets\n",
    "from tweepy import OAuthHandler # Authentication\n",
    "from textblob import TextBlob # provides text mining, text analysis and text processing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# keys and tokens from the Twitter Dev Console\n",
    "consumer_key = 'a0'\n",
    "consumer_secret = 'a1'\n",
    "access_token = 'a2'\n",
    "access_token_secret = 'a3'\n",
    "# create OAuthHandler object\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "# set access token and secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "# create tweepy API object to fetch tweets\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_sentiment(tweet):\n",
    "    analysis = TextBlob(tweet)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity <0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_tweets(query):\n",
    "\n",
    "    tweets = []\n",
    "\n",
    "    # call twitter api to fetch tweets\n",
    "    fetched_tweets = api.search_tweets(query,count=1000)\n",
    "\n",
    "    for tweet in fetched_tweets:\n",
    "        # empty dictionary to store required params of a tweet\n",
    "        parsed_tweet = {}\n",
    "\n",
    "        # saving text of tweet\n",
    "        parsed_tweet['text'] = tweet.text\n",
    "        # saving sentiment of tweet\n",
    "        parsed_tweet['sentiment'] = get_sentiment(tweet.text)\n",
    "\n",
    "        # appending parsed tweet to tweets list\n",
    "        if tweet.retweet_count > 0:\n",
    "            # if tweet has retweets, ensure that it is appended only once\n",
    "            if parsed_tweet not in tweets:\n",
    "                tweets.append(parsed_tweet)\n",
    "        else:\n",
    "            tweets.append(parsed_tweet)\n",
    "\n",
    "    # return parsed tweets\n",
    "    return tweets\n",
    "\n",
    "\n",
    "def analyze(querytext):\n",
    "    tweets = get_tweets(query = querytext)\n",
    "    print(\"Queries Text : \", querytext)\n",
    "    # picking positive tweets from tweets\n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive']\n",
    "    # percentage of positive tweets\n",
    "    print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets)))\n",
    "    # picking negative tweets from tweets\n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative']\n",
    "    # percentage of negative tweets\n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets)))\n",
    "    # percentage of neutral tweets\n",
    "    print(\"Neutral tweets percentage: {} %\".format(100*(len(tweets) - len(ntweets) - len(ptweets))/len(tweets)))\n",
    "    print(\"\\n\\n Total Tweets:\",len(tweets))\n",
    "    # printing first 5 positive tweets\n",
    "    print(\"\\n\\nPositive tweets:\")\n",
    "    for tweet in ptweets[:5]:\n",
    "        print(tweet['text'])\n",
    "\n",
    "    # printing first 5 negative tweets\n",
    "    print(\"\\n\\nNegative tweets:\")\n",
    "    for tweet in ntweets[:5]:\n",
    "        print(tweet['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Authentication Method: OAuth 2.0\n",
    "Instead of using OAuth 1.0a (which requires all four credentials), there is now OAuth 2.0 (which only requires a bearer token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries Text :  chocolate\n",
      "Positive tweets percentage: 27.272727272727273 %\n",
      "Negative tweets percentage: 11.688311688311689 %\n",
      "Neutral tweets percentage: 61.03896103896104 %\n",
      "\n",
      "\n",
      " Total Tweets: 77\n",
      "\n",
      "\n",
      "Positive tweets:\n",
      "RT @clefs27: #Âú∞Á∏õÂ∞ëÂπ¥Ëä±Â≠ê„Åè„Çì\n",
      "‚ÄúThe Nightingale and the Rose‚ÄùÔºå‚ÄúSleeping Beauty‚Äùand Valentine's chocolate https://t.co/uQsJbkcZFp\n",
      "RT @SylvanianUK: It‚Äôs a beautiful day to tend to the veggie patch! ‚òÄÔ∏è\n",
      "\n",
      "What kind of vegetables do you think the Chocolate Rabbit family are‚Ä¶\n",
      "@Bar_stolas Stunning cocktail!! I want to try it so much. I love the name too!ü§©üòçüíñ Is that coconut shavings or white‚Ä¶ https://t.co/f7NjnSVS65\n",
      "hot chocolate cinderella üòîü§çüòç\n",
      "@thelanyamarie Beautiful chocolate\n",
      "\n",
      "\n",
      "Negative tweets:\n",
      "what do you have in common with me? \n",
      "\n",
      "birth month: april \n",
      "birth date: 27\n",
      " height: 163-164 cm \n",
      " zodiac: taurus \n",
      "hair‚Ä¶ https://t.co/IO3xdzVdQ1\n",
      "RT @pledis_17jp: [#SEVENTEEN JAPAN NEWS]\n",
      "„ÄéSEVENTEEN TOUR 'FOLLOW' TO JAPAN„ÄèÁâπË®≠„Éö„Éº„Ç∏„Ç™„Éº„Éó„É≥ÔºÅ\n",
      "„Éï„Ç°„É≥„ÇØ„É©„Éñ„Éª„Ç´„É©„É¢„Éê‰ºöÂì°„ÉÅ„Ç±„ÉÉ„ÉàÂÖàË°åÊäΩÈÅ∏Âèó‰ªòÊ±∫ÂÆöÔºÅ\n",
      "\n",
      "üîóË©≥„Åó„Åè„ÅØ„Åì„Å°„Çâ‚Üí https://t.co/vF‚Ä¶\n",
      "RT @mihyunsvibe: when she left a chocolate on mina's bed with a note saying ''mina unnie don't get sick'' https://t.co/LEC8cKCqJP\n",
      "RT @simonharris_mbd: Of course Universal Basic Income is a bad idea. Anything designed to alleviate the utter shitness of existence is a ba‚Ä¶\n",
      "would rather drink poison than eat dark chocolate without washing it down with something\n"
     ]
    }
   ],
   "source": [
    "analyze('chocolate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries Text :  water resources\n",
      "Positive tweets percentage: 48.214285714285715 %\n",
      "Negative tweets percentage: 3.5714285714285716 %\n",
      "Neutral tweets percentage: 48.214285714285715 %\n",
      "\n",
      "\n",
      " Total Tweets: 56\n",
      "\n",
      "\n",
      "Positive tweets:\n",
      "This is wild, a company was stealing water from OKC during a time when OKC was moving water across the state from N‚Ä¶ https://t.co/Yw2JCjvMmc\n",
      "RT @BashirAhmaad: President Muhammadu Buhari will, among many other things, be remembered for:\n",
      "\n",
      "1. Legislative Reform\n",
      "\n",
      "2. Executive Orders‚Ä¶\n",
      "RT @TardaKE: This is aimed at promoting possible  collaborations by these Organisations in the use of satellite technologies for  early flo‚Ä¶\n",
      "@Atomic_1979 Asian carp fly out of the water with any disturbance and they over populate taking resources from a lo‚Ä¶ https://t.co/K80hUl04H8\n",
      "RT @TardaKE: @Tardake staff were taken through a capacity building in real time monitoring of water resources using GEOGloWS tool. https://‚Ä¶\n",
      "\n",
      "\n",
      "Negative tweets:\n",
      "@MdVet4 @YHyperbole @natalie_allison who makes the roads? the schools? who regulates food and water and other resou‚Ä¶ https://t.co/RWnE8Nloyi\n",
      "RT @Climateopp_Pod: By 2025, half the world's population will face water stress due to climate change and other factors. \n",
      "\n",
      "It's time to inn‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "analyze('water resources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries Text :  automatic watch\n",
      "Positive tweets percentage: 55.55555555555556 %\n",
      "Negative tweets percentage: 11.11111111111111 %\n",
      "Neutral tweets percentage: 33.333333333333336 %\n",
      "\n",
      "\n",
      " Total Tweets: 36\n",
      "\n",
      "\n",
      "Positive tweets:\n",
      "San Martin Men Watch 38.5mm Vintage Pilot NH35 Automatic Mechanical Simple Military Style Light Yellow Dial 10 Bar‚Ä¶ https://t.co/wL37eDb3uM\n",
      "FORWARD Automatic Tourbillon Men`s Mechanical Watch 3Bar Waterproof Multifunctional Luminous Sun Moon Star New Luxu‚Ä¶ https://t.co/LGDMCs5PuH\n",
      "ad eBay - Orient 3 Stars Automatic Black Dial Stainless Steel Lady's Watch FNQ1S003B9 https://t.co/sULmzh41zI https://t.co/KM4jFx95lw\n",
      "RT @VitaeLondon: The special Ada Gun Metal V1 Automatic watch draws inspiration from Ada, a town in Ghana. Our support for education in thi‚Ä¶\n",
      "RT @editshaymur: I added automatic english and spanish subs to the interview if you don't watched it still (it's full)\n",
      "https://t.co/iz59QNu‚Ä¶\n",
      "\n",
      "\n",
      "Negative tweets:\n",
      "ad eBay - Hermes H08 Limited Edition Madison Automatic Watch Titanium and Ceramic with Rub https://t.co/CJlg3SOSCm https://t.co/WUwuV1Js0f\n",
      "RT @StarWarsOnly2: Sometimes it‚Äôs like people dumb themselves down to make a stupid take\n",
      "If you‚Äôve ever watched ANH they state multiple tim‚Ä¶\n",
      "ad eBay - [Newly Upgraded] Automatic Double Watch Winder in Black https://t.co/Z7fb9Sg65F https://t.co/QbBzuYlQUU\n",
      "Tandorio 200m Waterproof 39MM Titanium Watch Case Black Dial Luminous NH35A PT5000 Movement Watch Automatic Men's L‚Ä¶ https://t.co/99xsNQOoFT\n"
     ]
    }
   ],
   "source": [
    "analyze('automatic watch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-trained models perform sentiment analysis based on data provided to them.\n",
    "Hugging face transformers are one such example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278e47bc7e4e40b0ba2c0dd57bb102ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/949 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ca2f551c344956baeeb12dd7bfeb0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd7cbb4d0354fad8fa1206f51c163a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/338 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5c10bf2c614e5f8377e83227b2e776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)solve/main/vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5f51c118254560ab77d7038797258e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)solve/main/bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3cb02073234da18ad01680fc30c319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)in/added_tokens.json:   0%|          | 0.00/22.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778ec8b0958f4dd89590a45108946d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)cial_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "# using a pre-trained model\n",
    "bert1 = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEG', 'score': 0.8680887222290039}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert1(\"It was acceptable elsewhere but here, this characteristic behaviour was looked down upon and immediate action was warranted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
